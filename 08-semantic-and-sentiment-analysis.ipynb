{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet\n",
    "\n",
    "WordNet is a huge database for the english language.\n",
    "\n",
    "## Synsets\n",
    "\n",
    "Synset is a collection or set of data entities that are considered to be semantically similar.\n",
    "\n",
    "## Repo\n",
    "https://github.com/dipanjanS/text-analytics-with-python/tree/master/Old-First-Edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Synsets: 5\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "\n",
    "term = 'fruit'\n",
    "synsets = wn.synsets(term)\n",
    "print('Total Synsets:', len(synsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset: Synset('fruit.n.01')\n",
      "Part of Speech: noun.plant\n",
      "Definition: the ripened reproductive body of a seed plant\n",
      "Lemmas: ['fruit']\n",
      "Examples: []\n",
      "\n",
      "Synset: Synset('yield.n.03')\n",
      "Part of Speech: noun.artifact\n",
      "Definition: an amount of a product\n",
      "Lemmas: ['yield', 'fruit']\n",
      "Examples: []\n",
      "\n",
      "Synset: Synset('fruit.n.03')\n",
      "Part of Speech: noun.event\n",
      "Definition: the consequence of some effort or action\n",
      "Lemmas: ['fruit']\n",
      "Examples: ['he lived long enough to see the fruit of his policies']\n",
      "\n",
      "Synset: Synset('fruit.v.01')\n",
      "Part of Speech: verb.creation\n",
      "Definition: cause to bear fruit\n",
      "Lemmas: ['fruit']\n",
      "Examples: []\n",
      "\n",
      "Synset: Synset('fruit.v.02')\n",
      "Part of Speech: verb.creation\n",
      "Definition: bear fruit\n",
      "Lemmas: ['fruit']\n",
      "Examples: ['the trees fruited early this year']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for synset in synsets:\n",
    "    print('Synset:', synset)\n",
    "    print('Part of Speech:', synset.lexname())\n",
    "    print('Definition:', synset.definition())\n",
    "    print('Lemmas:', synset.lemma_names())\n",
    "    print('Examples:', synset.examples())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entailments\n",
    "\n",
    "The term entailments usually refers to some event or action that logically involves or is associated with some other action or event that has taken place or will take place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('walk.v.01') -- entails --> [Synset('step.v.01')]\n",
      "Synset('eat.v.01') -- entails --> [Synset('chew.v.01'), Synset('swallow.v.01')]\n",
      "Synset('digest.v.01') -- entails --> [Synset('consume.v.02')]\n"
     ]
    }
   ],
   "source": [
    "for action in ['walk', 'eat', 'digest']:\n",
    "    action_syn = wn.synsets(action, pos='v')[0]\n",
    "    print(action_syn, '-- entails -->', action_syn.entailments())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homonyms and Homographs\n",
    "\n",
    "Homonyms refer to words or terms having the same written form or pronunciation but different meanings. Homonyms are a superset of homographs, which are words with same spelling but may have different pronunciation and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank.n.01 - sloping land (especially the slope beside a body of water)\n",
      "depository_financial_institution.n.01 - a financial institution that accepts deposits and channels the money into lending activities\n",
      "bank.n.03 - a long ridge or pile\n",
      "bank.n.04 - an arrangement of similar objects in a row or in tiers\n",
      "bank.n.05 - a supply or stock held in reserve for future use (especially in emergencies)\n",
      "bank.n.06 - the funds held by a gambling house or the dealer in some gambling games\n",
      "bank.n.07 - a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
      "savings_bank.n.02 - a container (usually with a slot in the top) for keeping money at home\n",
      "bank.n.09 - a building in which the business of banking transacted\n",
      "bank.n.10 - a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
      "bank.v.01 - tip laterally\n",
      "bank.v.02 - enclose with a bank\n",
      "bank.v.03 - do business with a bank or keep an account at a bank\n",
      "bank.v.04 - act as the banker in a game or in gambling\n",
      "bank.v.05 - be in the banking business\n",
      "deposit.v.02 - put into a bank account\n",
      "bank.v.07 - cover with ashes so to control the rate of burning\n",
      "trust.v.01 - have confidence or faith in\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('bank'):\n",
    "    print(synset.name(), '-', synset.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synonyms and antonyms\n",
    "\n",
    "Synonyms are words having similar meaning and context, and antonyms are words having opposite or contrasting meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonym: large.a.01\n",
      "Definition: above average in size or number or quantity or magnitude or extent\n",
      "Antonym: small.a.01\n",
      "Definition: limited or below average in number or quantity or magnitude or extent\n"
     ]
    }
   ],
   "source": [
    "term = 'large'\n",
    "synsets = wn.synsets(term)\n",
    "adj_large = synsets[1]\n",
    "adj_large = adj_large.lemmas()[0]\n",
    "adj_large_synonym = adj_large.synset()\n",
    "adj_large_antonym = adj_large.antonyms()[0].synset()\n",
    "\n",
    "# Print synonym and antonym.\n",
    "print('Synonym:', adj_large_synonym.name())\n",
    "print('Definition:', adj_large_synonym.definition())\n",
    "print('Antonym:', adj_large_antonym.name())\n",
    "print('Definition:', adj_large_antonym.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonym: rich_people.n.01\n",
      "Definition: people who have possessions and wealth (considered as a group)\n",
      "Antonym: poor_people.n.01\n",
      "Definition: people without possessions or wealth (considered as a group)\n",
      "Synonym: rich.a.01\n",
      "Definition: possessing material wealth\n",
      "Antonym: poor.a.02\n",
      "Definition: having little money or few possessions\n",
      "Synonym: rich.a.02\n",
      "Definition: having an abundant supply of desirable qualities or substances (especially natural resources)\n",
      "Antonym: poor.a.04\n",
      "Definition: lacking in specific resources, qualities or substances\n"
     ]
    }
   ],
   "source": [
    "term = 'rich'\n",
    "synsets = wn.synsets(term)[:3]\n",
    "\n",
    "# Print synonym and antonym for different synsets.\n",
    "for synset in synsets:\n",
    "    rich = synset.lemmas()[0]\n",
    "    rich_synonym = rich.synset()\n",
    "    rich_antonym = rich.antonyms()[0].synset()\n",
    "    \n",
    "    print('Synonym:', rich_synonym.name())\n",
    "    print('Definition:', rich_synonym.definition())\n",
    "\n",
    "\n",
    "    print('Antonym:', rich_antonym.name())\n",
    "    print('Definition:', rich_antonym.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyponyms and Hypernyms\n",
    "\n",
    "Hyponym refers to entities or concepts that are a subclass of a higher order concept or entity and have very specific sense or context compared to its superclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tree.n.01\n",
      "Definition: a tall perennial woody plant having a main trunk and branches forming a distinct elevated crown; includes both gymnosperms and angiosperms\n",
      "Total Hyponyms: 180\n",
      "Sample Hyponyms\n",
      "aalii.n.01 - a small Hawaiian tree with hard dark wood\n",
      "acacia.n.01 - any of various spiny trees or shrubs of the genus Acacia\n",
      "african_walnut.n.01 - tropical African timber tree with wood that resembles mahogany\n",
      "albizzia.n.01 - any of numerous trees of the genus Albizia\n",
      "alder.n.02 - north temperate shrubs or trees having toothed leaves and conelike fruit; bark is used in tanning and dyeing and the wood is rot-resistant\n",
      "angelim.n.01 - any of several tropical American trees of the genus Andira\n",
      "angiospermous_tree.n.01 - any tree having seeds and ovules contained in the ovary\n",
      "anise_tree.n.01 - any of several evergreen shrubs and small trees of the genus Illicium\n",
      "arbor.n.01 - tree (as opposed to shrub)\n",
      "aroeira_blanca.n.01 - small resinous tree or shrub of Brazil\n"
     ]
    }
   ],
   "source": [
    "term = 'tree'\n",
    "synsets = wn.synsets(term)\n",
    "tree = synsets[0]\n",
    "\n",
    "# Print the entity and its meaning.\n",
    "print('Name:', tree.name())\n",
    "print('Definition:', tree.definition())\n",
    "\n",
    "# Print total hyponyms and some sample hyponyms for 'tree'.\n",
    "hyponyms = tree.hyponyms()\n",
    "print('Total Hyponyms:', len(hyponyms))\n",
    "print('Sample Hyponyms')\n",
    "for hyponym in hyponyms[:10]:\n",
    "    print(hyponym.name(), '-', hyponym.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('woody_plant.n.01')]\n"
     ]
    }
   ],
   "source": [
    "hypernyms = tree.hypernyms()\n",
    "print(hypernyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Hypernym paths: 1\n"
     ]
    }
   ],
   "source": [
    "# Get total hierarchy pathways for tree.\n",
    "hypernym_paths = tree.hypernym_paths()\n",
    "print('Total Hypernym paths:', len(hypernym_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernym Hierarchy\n",
      "entity.n.01 -> physical_entity.n.01 -> object.n.01 -> whole.n.02 -> living_thing.n.01 -> organism.n.01 -> plant.n.02 -> vascular_plant.n.01 -> woody_plant.n.01 -> tree.n.01\n"
     ]
    }
   ],
   "source": [
    "# Print the entire hypernym hierarchy.\n",
    "print('Hypernym Hierarchy')\n",
    "print(' -> '.join(synset.name() for synset in hypernym_paths[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holonyms and Meronyms\n",
    "\n",
    "\n",
    "Holonyms are entities that contains a specific entity of our interest. Basically holonyms refers to the relationship between a term or entity that denotes the whole and a term denoting a specific part of the whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total member holonyms: 1\n",
      "Member holonyms for [tree]:-\n",
      "forest.n.01 - the trees and other plants in a large densely wooded area\n"
     ]
    }
   ],
   "source": [
    "member_holonyms = tree.member_holonyms()\n",
    "print('Total member holonyms:', len(member_holonyms))\n",
    "print('Member holonyms for [tree]:-')\n",
    "for holonym in member_holonyms:\n",
    "    print(holonym.name(), '-', holonym.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Part Meronyms: 5\n",
      "Part Meronyms for [tree]:-\n",
      "burl.n.02 - a large rounded outgrowth on the trunk or branch of a tree\n",
      "crown.n.07 - the upper branches and leaves of a tree or other plant\n",
      "limb.n.02 - any of the main branches arising from the trunk or a bough of a tree\n",
      "stump.n.01 - the base part of a tree that remains standing after the tree has been felled\n",
      "trunk.n.01 - the main stem of a tree; usually covered with bark; the bole is usually the part that is commercially useful for lumber\n"
     ]
    }
   ],
   "source": [
    "# Part based meronyms for tree.\n",
    "part_meronyms = tree.part_meronyms()\n",
    "print('Total Part Meronyms:', len(part_meronyms))\n",
    "print('Part Meronyms for [tree]:-')\n",
    "for meronym in part_meronyms:\n",
    "    print(meronym.name(), '-', meronym.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total substance meronyms: 2\n",
      "heartwood.n.01 - the older inactive central wood of a tree or woody plant; usually darker and denser than the surrounding sapwood\n",
      "sapwood.n.01 - newly formed outer wood lying between the cambium and the heartwood of a tree or woody plant; usually light colored; active in water conduction\n"
     ]
    }
   ],
   "source": [
    "# Substance based meronyms for tree.\n",
    "substance_meronyms = tree.substance_meronyms()\n",
    "print('Total substance meronyms:', len(substance_meronyms))\n",
    "for meronym in substance_meronyms:\n",
    "    print(meronym.name(), '-', meronym.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic relationships and similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree - a tall perennial woody plant having a main trunk and branches forming a distinct elevated crown; includes both gymnosperms and angiosperms\n",
      "lion - large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n",
      "tiger - large feline of forests in most of Asia having a tawny coat with black stripes; endangered\n",
      "cat - feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n",
      "dog - a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n"
     ]
    }
   ],
   "source": [
    "tree = wn.synset('tree.n.01')\n",
    "lion = wn.synset('lion.n.01')\n",
    "tiger = wn.synset('tiger.n.02')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog = wn.synset('dog.n.01')\n",
    "\n",
    "# Create entities and extract names and definitions.\n",
    "entities = [tree, lion, tiger, cat, dog]\n",
    "entity_names = [entity.name().split('.')[0] for entity in entities]\n",
    "entity_definitions = [entity.definition() for entity in entities]\n",
    "\n",
    "# Print entities and their definitions.\n",
    "for entity, definition in zip(entity_names, entity_definitions):\n",
    "    print(entity, '-', definition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>tiger</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>tree</td>\n",
       "      <td>organism</td>\n",
       "      <td>organism</td>\n",
       "      <td>organism</td>\n",
       "      <td>organism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>organism</td>\n",
       "      <td>lion</td>\n",
       "      <td>big_cat</td>\n",
       "      <td>feline</td>\n",
       "      <td>carnivore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>organism</td>\n",
       "      <td>big_cat</td>\n",
       "      <td>tiger</td>\n",
       "      <td>feline</td>\n",
       "      <td>carnivore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>organism</td>\n",
       "      <td>feline</td>\n",
       "      <td>feline</td>\n",
       "      <td>cat</td>\n",
       "      <td>carnivore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>organism</td>\n",
       "      <td>carnivore</td>\n",
       "      <td>carnivore</td>\n",
       "      <td>carnivore</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tree       lion      tiger        cat        dog\n",
       "tree       tree   organism   organism   organism   organism\n",
       "lion   organism       lion    big_cat     feline  carnivore\n",
       "tiger  organism    big_cat      tiger     feline  carnivore\n",
       "cat    organism     feline     feline        cat  carnivore\n",
       "dog    organism  carnivore  carnivore  carnivore        dog"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_hypernyms = []\n",
    "for entity in entities:\n",
    "    # Get pairwise lowest common hypernyms.\n",
    "    common_hypernyms.append([entity.lowest_common_hypernyms(compared_entity)[0].name().split('.')[0]\n",
    "                             for compared_entity in entities])\n",
    "    \n",
    "# Build pairwise lower common hypernym matrix.\n",
    "common_hypernym_frame = pd.DataFrame(common_hypernyms,\n",
    "                                     index=entity_names,\n",
    "                                     columns=entity_names)\n",
    "\n",
    "# Print the matrix.\n",
    "common_hypernym_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>tiger</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tree  lion  tiger   cat   dog\n",
       "tree   1.00  0.07   0.07  0.08  0.12\n",
       "lion   0.07  1.00   0.33  0.25  0.17\n",
       "tiger  0.07  0.33   1.00  0.25  0.17\n",
       "cat    0.08  0.25   0.25  1.00  0.20\n",
       "dog    0.12  0.17   0.17  0.20  1.00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = []\n",
    "for entity in entities:\n",
    "    # Get pairwise similarities.\n",
    "    similarities.append([round(entity.path_similarity(compared_entity), 2)\n",
    "                         for compared_entity in entities])\n",
    "\n",
    "# Build pairwise similarity matrix.\n",
    "similarity_frame = pd.DataFrame(similarities,\n",
    "                                index=entity_names,\n",
    "                                columns=entity_names)\n",
    "\n",
    "similarity_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word sense disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The fruits on that plant has ripened\n",
      "Word synset: Synset('fruit.n.01')\n",
      "Corresponding definition: the ripened reproductive body of a seed plant\n",
      "\n",
      "Sentence: He finally reaped the fruit of his hard work as he won the race\n",
      "Word synset: Synset('fruit.n.03')\n",
      "Corresponding definition: the consequence of some effort or action\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample text and word to disambiguate.\n",
    "samples = [('The fruits on that plant has ripened', 'n'),\n",
    "           ('He finally reaped the fruit of his hard work as he won the race', 'n')]\n",
    "word = 'fruit'\n",
    "\n",
    "# Perform word sense disambiguation.\n",
    "for sentence, pos_tag in samples:\n",
    "    word_syn = lesk(word_tokenize(sentence.lower()), word, pos_tag)\n",
    "    print('Sentence:', sentence)\n",
    "    print('Word synset:', word_syn)\n",
    "    print('Corresponding definition:', word_syn.definition())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Lead is a very soft, malleable metal\n",
      "Word synset: Synset('lead.n.02')\n",
      "Corresponding definition: a soft heavy toxic malleable metallic element; bluish white when freshly cut but tarnishes readily to dull grey\n",
      "\n",
      "Sentence: John is the actor who plays the lead in that movie\n",
      "Word synset: Synset('star.n.04')\n",
      "Corresponding definition: an actor who plays a principal role\n",
      "\n",
      "Sentence: This road leads to nowhere\n",
      "Word synset: Synset('run.v.23')\n",
      "Corresponding definition: cause something to pass or lead somewhere\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample text and word to disambiguate.\n",
    "samples = [('Lead is a very soft, malleable metal', 'n'),\n",
    "           ('John is the actor who plays the lead in that movie', 'n'),\n",
    "           ('This road leads to nowhere', 'v')]\n",
    "word = 'lead'\n",
    "\n",
    "# Perform word sense disambiguation.\n",
    "for sentence, pos_tag in samples:\n",
    "    word_syn = lesk(word_tokenize(sentence.lower()), word, pos_tag)\n",
    "    print('Sentence:', sentence)\n",
    "    print('Word synset:', word_syn)\n",
    "    print('Corresponding definition:', word_syn.definition())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition\n",
    "NER, also known as entity chunking/extraction is a popular technique used in information extraction to identify and segment named entities and classify or categorize them under various predefined classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Bayern Munich, or FC Bayern, is a German sports club based in Munich, \n",
    "Bavaria, Germany. It is best known for its professional football team, \n",
    "which plays in the Bundesliga, the top tier of the German football \n",
    "league system, and is the most successful club in German football \n",
    "history, having won a record 26 national titles and 18 national cups. \n",
    "FC Bayern was founded in 1900 by eleven football players led by Franz John. \n",
    "Although Bayern won its first national championship in 1932, the club \n",
    "was not selected for the Bundesliga at its inception in 1963. The club \n",
    "had its period of greatest success in the middle of the 1970s when, \n",
    "under the captaincy of Franz Beckenbauer, it won the European Cup three \n",
    "times in a row (1974-76). Overall, Bayern has reached ten UEFA Champions \n",
    "League finals, most recently winning their fifth title in 2013 as part \n",
    "of a continental treble. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity Name</th>\n",
       "      <th>Entity Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FC Bayern</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Munich</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Munich</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bayern</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bavaria</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Franz John</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UEFA</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Overall</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Franz Beckenbauer</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>European</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bayern</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Entity Name   Entity Type\n",
       "0           FC Bayern  ORGANIZATION\n",
       "1              German           GPE\n",
       "2             Germany           GPE\n",
       "3              Munich           GPE\n",
       "4              Munich  ORGANIZATION\n",
       "5              Bayern           GPE\n",
       "6             Bavaria           GPE\n",
       "7          Franz John        PERSON\n",
       "8                UEFA  ORGANIZATION\n",
       "9             Overall           GPE\n",
       "10  Franz Beckenbauer        PERSON\n",
       "11         Bundesliga  ORGANIZATION\n",
       "12           European  ORGANIZATION\n",
       "13             Bayern        PERSON"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from module.normalization import parse_document\n",
    "import pandas as pd\n",
    "\n",
    "# Tokenize sentences.\n",
    "sentences = parse_document(text)\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence) \n",
    "                       for sentence in sentences]\n",
    "\n",
    "# Tag sentences and use nltk's Named Entity Chunker.\n",
    "tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n",
    "ne_chunked_sents = [nltk.ne_chunk(tagged) for tagged in tagged_sentences]\n",
    "\n",
    "\n",
    "# Extract all named entities.\n",
    "named_entities = []\n",
    "for ne_tagged_sentence in ne_chunked_sents:\n",
    "    for tagged_tree in ne_tagged_sentence:\n",
    "        # Extract only chunks having NE labels.\n",
    "        if hasattr(tagged_tree, 'label'):\n",
    "            entity_name = ' '.join(c[0] for c in tagged_tree.leaves()) # Get NE name.\n",
    "            entity_type = tagged_tree.label() # Get NE category.\n",
    "            named_entities.append((entity_name, entity_type))\n",
    "# Get unique named entities.\n",
    "named_entities = list(set(named_entities))\n",
    "\n",
    "# Store named entities in a data frame.\n",
    "entity_frame = pd.DataFrame(named_entities, \n",
    "                            columns=['Entity Name', 'Entity Type'])\n",
    "entity_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: SKIP Standford NER Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propositional Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: He is hungry\n",
      "Q: He will eat a sandwich\n",
      "\n",
      "Expression Outcomes:-\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>(P &amp; Q)</th>\n",
       "      <th>(P | Q)</th>\n",
       "      <th>(P -&gt; Q)</th>\n",
       "      <th>(P &lt;-&gt; Q)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       P      Q  (P & Q)  (P | Q)  (P -> Q)  (P <-> Q)\n",
       "0  False  False    False    False      True       True\n",
       "1  False   True    False     True      True      False\n",
       "2   True  False    False     True     False      False\n",
       "3   True   True     True     True      True       True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign symbols and propositions.\n",
    "symbol_P = 'P'\n",
    "symbol_Q = 'Q'\n",
    "proposition_P = 'He is hungry'\n",
    "proposition_Q = 'He will eat a sandwich'\n",
    "\n",
    "# Assign various truth values to the proposition.\n",
    "p_statuses = [False, False, True, True]\n",
    "q_statuses = [False, True, False, True]\n",
    "\n",
    "# Assign the various expressions combining the logical operators.\n",
    "conjunction = '(P & Q)'\n",
    "disjunction = '(P | Q)'\n",
    "implication = '(P -> Q)'\n",
    "equivalence = '(P <-> Q)'\n",
    "expressions = [conjunction, disjunction, implication, equivalence]\n",
    "\n",
    "# Evaluate each expression using propositional logic.\n",
    "results = []\n",
    "\n",
    "for status_p, status_q in zip(p_statuses, q_statuses):\n",
    "    dom = set([])\n",
    "    val = nltk.Valuation([(symbol_P, status_p), \n",
    "                          (symbol_Q, status_q)])\n",
    "    assignments = nltk.Assignment(dom)\n",
    "    model = nltk.Model(dom, val)\n",
    "    row = [status_p, status_q]\n",
    "    for expression in expressions:\n",
    "        # Evaluate each expression based on proposition truth values.\n",
    "        result = model.evaluate(expression, assignments)\n",
    "        row.append(result)\n",
    "    results.append(row)\n",
    "\n",
    "# Build the result table.\n",
    "columns = [symbol_P, symbol_Q, conjunction, \n",
    "           disjunction, \n",
    "           implication,\n",
    "           equivalence]\n",
    "\n",
    "result_frame = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Display results.\n",
    "\n",
    "print('P:', proposition_P)\n",
    "print('Q:', proposition_Q)\n",
    "print()\n",
    "print('Expression Outcomes:-')\n",
    "result_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from module.normalization import normalize_corpus\n",
    "from module.utils import build_feature_matrix, display_evaluation_metrics, display_confusion_matrix, display_classification_report\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('movie_reviews.csv')\n",
    "dataset = dataset.head(10_000)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1_000 # 35_000\n",
    "train_data = dataset[:n]\n",
    "test_data = dataset[n:n+n]\n",
    "\n",
    "train_reviews = np.array(train_data['review'])\n",
    "train_sentiments = np.array(train_data['sentiment'])\n",
    "test_reviews = np.array(test_data['review'])\n",
    "test_sentiments = np.array(test_data['sentiment'])\n",
    "\n",
    "# Prepare sample dataset for experiments.\n",
    "# sample_docs = [100, 5817, 7626, 7356, 1008, 7155, 3533, 13010]\n",
    "sample_docs = [100, 581, 762, 735, 100, 715, 353, 130]\n",
    "sample_data = [(test_reviews[index], test_sentiments[index])\n",
    "               for index in sample_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization.\n",
    "norm_train_reviews = normalize_corpus(train_reviews, lemmatize=True, only_text_chars=True)\n",
    "\n",
    "# Feature extraction.\n",
    "vectorizer, train_features = build_feature_matrix(documents=norm_train_reviews,\n",
    "                                                  feature_type='tfidf',\n",
    "                                                  ngram_range=(1, 1),\n",
    "                                                  min_df=0.0,\n",
    "                                                  max_df=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=200, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Build the model.\n",
    "svm = SGDClassifier(loss='hinge', max_iter=200)\n",
    "svm.fit(train_features, train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:-\n",
      "I watch them all.<br /><br />It's not better than the amazing ones (_Strictly Ballroom_, _Shall we dance?_ (Japanese version), but it's completely respectable and pleasingly different in parts.<br /><br />I am an English teacher and I find some of the ignorance about language in some of these reviews rather upsetting. For example: the \"name should scream don't watch. 'How she move.' Since when can movie titles ignore grammar?\" <br /><br />There is nothing inherently incorrect about Caribbean English grammar. It's just not Canadian standard English grammar. Comments about the dialogue seem off to me. I put on the subtitles because I'm a Canadian standard English speaker, so I just AUTOMATICALLY assumed that I would have trouble understanding all of it. It wasn't all that difficult and it gave a distinctly different flavour as the other step movies I have seen were so American.<br /><br />I loved that this movie was set in Toronto and, in fact, wish it was even more clearly set there. I loved that the heroine was so atypically cast. I enjoyed the stepping routines. I liked the driven Mum character. I felt that many of the issues in the movie were addressed more subtly than is characteristic of dance movies.<br /><br />In summary, if you tend to like dance movies, then this is a decent one. If you have superiority issues about the grammar of the English standard you grew up speaking, your narrow mind may have difficulty enjoying this movie.\n",
      "Actual labeled sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Review:-\n",
      "A gem of a British caper-comedy. Poor American schlub Pinky Green (Richard Jordan, playing another bad guy but this time an adorable one) gets out of a British jail and tries to go straight, but his maintenance man job in a bank is too attractive for his never-reformed criminal friends, headed up by a really nasty Ivan (David Niven in one of his last roles). Pinky resists, but the lure of all that money is just too much for him. Things unravel and reravel and it's all joyous to watch. Jordan must have played 20 bad guys in his career, but he never played the same one twice - this one is just too lovable to hate. Niven never played a slicker bad guy, oil all over. Two fine actors we've lost that I wish we had back.\n",
      "Actual labeled sentiment: positive\n",
      "Predicted sentiment: negative\n",
      "\n",
      "Review:-\n",
      "The above line sums it up pretty good. The best assets of the comics are it's visual gags and word-jokes (the latter of which are almost impossible to translate, which is why the comics are at their best in their original language).<br /><br />Both are quite hard to capture in film, which is why those will never be as good as the comics. Movies are simply a different medium than comics. With that in mind, this movie does surprisingly well in capturing the fun of the comic.<br /><br />The word gags are bearable, and sometimes even funny (Debouze does an Amelie reference!). I have to mention that I watched the french version. If you don't watch the french version or your lack of understanding of the french language limits you to the subtitles, the word jokes will probably suck.<br /><br />The slapstick is okay as well; it's a very simple form of humor, and not really funny when you're older than twelve, but it captures the spirit of the comicbooks. The other visual jokes are the movie's saving grace for the older audience, as their often quite funny.<br /><br />The acting is totally over the top, but again, that's not annoying at all as it captures the spirit of the comicbooks. Only Depardieu and Clavier don't really overact, which might be the reason some people think they didn't enjoy their roles (I didn't notice a thing). On the other hand Jamel Debouze and especially Claude Rich turn overacting into an artform. It's actually fun to watch. Again, I fear it wouldn't be nearly as funny when the voices are dubbed.<br /><br />Overall not a bad movie at all, much better than the previous one. It's not a classic and it doesn't dethrone The Twelve Tasks of Asterix as my favourite Asterix movie, but it's still worth seeing. The french version, that is. 7/10\n",
      "Actual labeled sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Review:-\n",
      "Komodo vs. Cobra starts as 'One Planet' environmentalist Jerry Ryan (Ryan McTavish) & his girlfriend Carrie (Renee Talbert) hire Captain Michael Stoddard (executive producer Michael Paré) to take them to an island in the South Pacific, at first Stoddard is reluctant since the island is a top secret military research base but soon changes his mind when a load of cash is offered. Along with TV news reporter Sandra Crescent (Jeri Manthey) they set sail for the island & once ashore find out that the military have been funding illegal DNA genetic experiments which have resulted in huge Komodo Dragon's & King Cobra's that have eaten almost every other living thing there & Stoddard & co are next on the menu...<br /><br />Co-written & directed by the ever awful Jim Wynorski under his Jay Andrews pseudonym this is just plain awful, this is just plain hard to sit through & is even worse than the usual rubbish 'Creature Features' the Sci-Fi Channel have the nerve to air if that's possible. The script is terrible, predictable & utterly boring, some giant monsters of some sort are created by scientists messing around with DNA, a group of people are trapped with said monsters & have to try to escape being eaten. That's it, that's the whole plot of Komodo vs. Cobra, maybe this was trying to rip-off AVP: Alien vs. Predator (2004) with the title but all the 'vs.' bit amounts to is a rubbish thirty second stand-off between the two titular beasts at the very end, boring as hell & surely a big disappointment to anyone hoping to have a full on monster mash. The character's are poor, the dialogue is awful, the pace is slow, the story is predictable & cliché ridden & the whole film just sucks really with a lazy script that states wrongly that both Komodo Dragon's & Cobra's are amphibious which they are not. Hell, Komodo vs. Cobra isn't even worth watching for any unintentional laughs since it's so dull & hardly anything ever happens although the sight of a woman hiding behind the smallest rock on the beach from the Cobra is quite funny for the wrong reasons.<br /><br />How does Wynorski keep getting directing jobs? He is probably consistently the worst director currently working, how can he keep getting fun sounding films set on beautiful locations with half decent casts & still churn out such an awful film? I think this was cut to get a PG or for it's TV showing since every time someone swears it's masked by a Parrot squeak! There's zero gore or violence & the monster scenes are limp, people just sort of stand there, the monsters just sort of stands there too hissing or roaring & that's about it. The CGI computer effects are terrible, this is really poor stuff that just looks horrible.<br /><br />With a supposed budget of about $450,000 this looks as cheap as it was, the Hawaiian locations are nice to look at but that's about it. The acting is poor from an uninterested looking cast.<br /><br />Komodo vs. Cobra is an absolutely terrible Sci-Fi Channel 'Creature Feature' from Jim Wynorski, films don't get much worse than this.\n",
      "Actual labeled sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "\n",
      "Review:-\n",
      "I watch them all.<br /><br />It's not better than the amazing ones (_Strictly Ballroom_, _Shall we dance?_ (Japanese version), but it's completely respectable and pleasingly different in parts.<br /><br />I am an English teacher and I find some of the ignorance about language in some of these reviews rather upsetting. For example: the \"name should scream don't watch. 'How she move.' Since when can movie titles ignore grammar?\" <br /><br />There is nothing inherently incorrect about Caribbean English grammar. It's just not Canadian standard English grammar. Comments about the dialogue seem off to me. I put on the subtitles because I'm a Canadian standard English speaker, so I just AUTOMATICALLY assumed that I would have trouble understanding all of it. It wasn't all that difficult and it gave a distinctly different flavour as the other step movies I have seen were so American.<br /><br />I loved that this movie was set in Toronto and, in fact, wish it was even more clearly set there. I loved that the heroine was so atypically cast. I enjoyed the stepping routines. I liked the driven Mum character. I felt that many of the issues in the movie were addressed more subtly than is characteristic of dance movies.<br /><br />In summary, if you tend to like dance movies, then this is a decent one. If you have superiority issues about the grammar of the English standard you grew up speaking, your narrow mind may have difficulty enjoying this movie.\n",
      "Actual labeled sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Review:-\n",
      "I got encouraged to watch this film because I've heard good word of it: it was supposed to be this thrilling true crime milestone, disturbing, shocking... all that jazz. Well, I am disturbed because I spent money on it, and I am shocked that something so God-awful actually got released. That's about it.<br /><br />This is a supposed \"new look\" at Charles Manson's family of insane loser junkies and their murders. But if this is a \"new look\" then it's probably \"new\" as in \"fresh and totally inept\": just watching it gave me a headache and I had to give up trying to make any sense of it or even understand just what the director intended it to be.<br /><br />I suppose I should say something about the plot but fact is, it was so stupid and incoherent that I barely remember if there even WAS a plot at all. There was something about a \"Manson tape\" delivered to a radio DJ (or a TV producer?), then an hour of pointless random footage of \"the family\" in '69, then the Polanski murders (looking like a bad school play) and finally some idiotic part about a bunch of skinheads getting drunk and beating the hell out of one another in an alley (I kid you not), and then it ended (thank God) (Don't ask me to make any sense of that, I'm just recalling what I saw!) The performances were terrible, too. And how difficult is it to make a convincing \"Manson\"? Get a short skinny scrawny bloke, put a dirty wig and a shaggy beard on him. There's your Manson. But this \"Manson\" doesn't even look right. He just looks like, uh, a bloke in a cheap wig and a glued on Santa beard painted black.<br /><br />Or maybe that's what this film is actually about: Manson's family didn't make any sense, so this film doesn't make any sense, either. It's symbolic! (Yeah, right) I'm still so angry at spending money on this I stopped my normal lurking on this site and registered just to vote 1 for this film and post this warning that will hopefully prevent others from spending their money on this garbage. Stay away from it, it's not even worth renting.<br /><br />PS. The recent US TV production \"Helter Skelter\" got bad reviews here but I saw it last month (I saw the 1976 original too) and let me tell you, compared to \"Manson Family\", that new Helter Skelter is BRILLIANT and FLAWLESS. And I was disappointed in it! That's how bad \"Manson Family\" is: it makes a flawed and mostly disappointing TV movie look perfect.\n",
      "Actual labeled sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "\n",
      "Review:-\n",
      "This movie tries to run away to the typical 'I'm fighting because I'm obliged to defend the fatherland. The NAZI's are all bad guys, I'm against them' (typical of German war movies). How? By not talking too much about it, and just referring the war and the POW's. Nevertheless I would like to see a German movie which would be something between the extremity of Come And See and the \"bad NAZI's\" Das Boot. I say this because, excluding this factor, the German movies are the best depicting 2nd world war and the German side. You easily see some of the German hierarchical relations, very different from the ones in US army.<br /><br />This is a movie which tries to get a real sight of what was Stalingrad, and I was not there, and I doubt most people were there now, but if I would choose one movie depicting this battle, for sure would not be the all American Enemy At The Gates. Why do I say this? Because even the best soldiers are not hero's, and given the conditions they may regard their own lives instead of the fatherland. This goes for all the ranks, and in the end you see von Paulus giving the example.\n",
      "Actual labeled sentiment: positive\n",
      "Predicted sentiment: negative\n",
      "\n",
      "Review:-\n",
      "I haven't had a chance to view the previous film, but from what I've read on other posts it was supposedly worse than this one, although I doubt that is possible. I'm a huge fan of the \"Zombie\" genre, and I am fascinated by the psychological aspects of viewing creatures, that for all intents and purposes are human, as an atrocity that is only worth shooting in the head. That said, HOTD 2 takes the \"Zombie\" movie to an all new low.<br /><br />Without giving any big spoilers (which I really should do just so you won't bother wasting your time actually watching this movie) I would like to express my utter contempt for the way the writers of this film portray our countries Special Forces. Gomer Pile could have probably survived longer than the \"Spec Ops\" soldiers in this film. For crying out loud they should have called them the Special Education Forces instead. If you are going to write a script where you send in an elite team to deal with an outbreak of zombies, at least have the soldiers be smarter than the walking corpses. I understand that you have to kill off some or most of the team, but you can find better ways to do it than having them set down their machine guns and walk over to lay a tender hand on the shoulder of the drooling crazy person rocking back and forth in the corner of the dark creepy basement.<br /><br />The writers actually try to take the whole zombie thing to a more high-tech level by making it a virus that they are searching for a vaccine for, and the idea has merit, if it wasn't stuck in the middle of such a ridiculous display of wayward film making. I mean come on, zombie films aren't exactly \"high art\", and the viewer expects some tongue-in-cheek cheesiness along with the gore and thrills, but HOTD 2 is the type of cheese that makes you turn the channel in disgust and awe of the sheer stupidity of the characters. If you are a zombie movie fan like me, please do yourself a favor and stay away from this one.\n",
      "Actual labeled sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize reviews.\n",
    "norm_test_reviews = normalize_corpus(test_reviews, lemmatize=True, only_text_chars=True)\n",
    "\n",
    "# Extract features.\n",
    "test_features = vectorizer.transform(norm_test_reviews)\n",
    "\n",
    "# Predict sentiment for sample docs from test data.\n",
    "for doc_index in sample_docs:\n",
    "    print('Review:-')\n",
    "    print(test_reviews[doc_index])\n",
    "    print('Actual labeled sentiment:', test_sentiments[doc_index])\n",
    "    doc_features = test_features[doc_index]\n",
    "    predicted_sentiment = svm.predict(doc_features)[0]\n",
    "    print('Predicted sentiment:', predicted_sentiment)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n",
      "Precision: 0.83\n",
      "Recall: 0.83\n",
      "F1 Score: 0.83\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive        420       84\n",
      "        negative         88      408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.83      0.83      0.83       504\n",
      "    negative       0.83      0.82      0.83       496\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.83      0.83      0.83      1000\n",
      "weighted avg       0.83      0.83      0.83      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alextanhongpin/Documents/python/nlp/text-analytics-with-python/module/utils.py:119: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  levels=[['Predicted:'], classes], labels=[[0, 0], [0, 1]]),\n",
      "/Users/alextanhongpin/Documents/python/nlp/text-analytics-with-python/module/utils.py:121: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  levels=[['Actual:'], classes], labels=[[0, 0], [0, 1]]))\n"
     ]
    }
   ],
   "source": [
    "# Predict the sentiment for test dataset movie reviews.\n",
    "predicted_sentiments = svm.predict(test_features)\n",
    "\n",
    "# Evaluate model prediction performance.\n",
    "# Show performance metrics.\n",
    "display_evaluation_metrics(true_labels=test_sentiments,\n",
    "                           predicted_labels=predicted_sentiments,\n",
    "                           positive_class='positive')\n",
    "\n",
    "# Show confusion matrix.\n",
    "display_confusion_matrix(true_labels=test_sentiments,\n",
    "                         predicted_labels=predicted_sentiments,\n",
    "                         classes=['positive', 'negative'])\n",
    "\n",
    "# Show detailed per-class classification report.\n",
    "display_classification_report(true_labels=test_sentiments,\n",
    "                              predicted_labels=predicted_sentiments,\n",
    "                              classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised lexicon-based techniques\n",
    "\n",
    "- AFINN lexicon\n",
    "- Bing Liu's lexicon\n",
    "- MPQA subjectivity lexicon\n",
    "- SentiWordNet\n",
    "- VADER lexicon\n",
    "- Pattern lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFINN Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "afn = Afinn(emoticons=True)\n",
    "afn.score('I really hated the plot of this movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afn.score('I really hated the plot of this movie :(')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive polarity score: 0.5\n",
      "Negative polarity score: 0.0\n",
      "Objective score: 0.5\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "# Get synset for 'good'.\n",
    "good = list(swn.senti_synsets('good', 'n'))[0]\n",
    "\n",
    "# Print synset sentiment scores.\n",
    "print('Positive polarity score:', good.pos_score())\n",
    "print('Negative polarity score:', good.neg_score())\n",
    "print('Objective score:', good.obj_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.normalization import normalize_accented_characters, strip_html\n",
    "import html\n",
    "\n",
    "def safe_list(l, i=0):\n",
    "    return l[i] if len(l) > i else None\n",
    "\n",
    "def analyze_sentiment_sentiwordnet_lexicon(review, verbose=False):\n",
    "    # Pre-process text.\n",
    "    review = normalize_accented_characters(review)\n",
    "    review = html.unescape(review.decode('utf-8'))\n",
    "    review = strip_html(review)\n",
    "    \n",
    "    # Tokenize and POS tag text tokens.\n",
    "    text_tokens = nltk.word_tokenize(review)\n",
    "    tagged_text = nltk.pos_tag(text_tokens)\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    \n",
    "    # Get word synsets based on POS tags.\n",
    "    # Get sentiment scores if synsets are found.\n",
    "    for word, tag in tagged_text:\n",
    "        ss_set = None\n",
    "        if 'NN' in tag and swn.senti_synsets(word, 'n'):\n",
    "            ss_set = safe_list(list(swn.senti_synsets(word, 'n')))\n",
    "        elif 'VB' in tag and swn.senti_synsets(word, 'v'):\n",
    "            ss_set = safe_list(list(swn.senti_synsets(word, 'v')))\n",
    "        elif 'JJ' in tag and swn.senti_synsets(word, 'a'):\n",
    "            ss_set = safe_list(list(swn.senti_synsets(word, 'a')))\n",
    "        elif 'RB' in tag and swn.senti_synsets(word, 'r'):\n",
    "            ss_set = safe_list(list(swn.senti_synsets(word, 'r')))\n",
    "        \n",
    "        if ss_set:\n",
    "            # If senti-synset is found.\n",
    "            # Add scores for all found synsets.\n",
    "            pos_score += ss_set.pos_score()\n",
    "            neg_score += ss_set.neg_score()\n",
    "            obj_score += ss_set.obj_score()\n",
    "            token_count += 1\n",
    "    \n",
    "    # Aggregate final scores.\n",
    "    final_score = pos_score - neg_score\n",
    "    norm_final_score = round(float(final_score)/token_count, 2)\n",
    "    final_sentiment = 'positive' if norm_final_score > 0 else 'negative'\n",
    "    if verbose:\n",
    "        norm_obj_score = round(float(obj_score) / token_count, 2)\n",
    "        norm_pos_score = round(float(pos_score) / token_count, 2)\n",
    "        norm_neg_score = round(float(neg_score) / token_count, 2)\n",
    "        \n",
    "        # To display results in a nice table.\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score, \n",
    "                                         norm_pos_score,\n",
    "                                         norm_neg_score,\n",
    "                                         norm_final_score]],\n",
    "                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'],\n",
    "                                                                     ['Predicted Sentiment',\n",
    "                                                                      'Objectivity',\n",
    "                                                                      'Positive',\n",
    "                                                                      'Negative',\n",
    "                                                                      'Overall']],\n",
    "                                                            codes=[[0,0,0,0,0], [0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "I watch them all.<br /><br />It's not better than the amazing ones (_Strictly Ballroom_, _Shall we dance?_ (Japanese version), but it's completely respectable and pleasingly different in parts.<br /><br />I am an English teacher and I find some of the ignorance about language in some of these reviews rather upsetting. For example: the \"name should scream don't watch. 'How she move.' Since when can movie titles ignore grammar?\" <br /><br />There is nothing inherently incorrect about Caribbean English grammar. It's just not Canadian standard English grammar. Comments about the dialogue seem off to me. I put on the subtitles because I'm a Canadian standard English speaker, so I just AUTOMATICALLY assumed that I would have trouble understanding all of it. It wasn't all that difficult and it gave a distinctly different flavour as the other step movies I have seen were so American.<br /><br />I loved that this movie was set in Toronto and, in fact, wish it was even more clearly set there. I loved that the heroine was so atypically cast. I enjoyed the stepping routines. I liked the driven Mum character. I felt that many of the issues in the movie were addressed more subtly than is characteristic of dance movies.<br /><br />In summary, if you tend to like dance movies, then this is a decent one. If you have superiority issues about the grammar of the English standard you grew up speaking, your narrow mind may have difficulty enjoying this movie.\n",
      "\n",
      "Labeled sentiment: positive\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.82     0.12     0.06    0.06\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "A gem of a British caper-comedy. Poor American schlub Pinky Green (Richard Jordan, playing another bad guy but this time an adorable one) gets out of a British jail and tries to go straight, but his maintenance man job in a bank is too attractive for his never-reformed criminal friends, headed up by a really nasty Ivan (David Niven in one of his last roles). Pinky resists, but the lure of all that money is just too much for him. Things unravel and reravel and it's all joyous to watch. Jordan must have played 20 bad guys in his career, but he never played the same one twice - this one is just too lovable to hate. Niven never played a slicker bad guy, oil all over. Two fine actors we've lost that I wish we had back.\n",
      "\n",
      "Labeled sentiment: positive\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            negative        0.77      0.1     0.13   -0.03\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "The above line sums it up pretty good. The best assets of the comics are it's visual gags and word-jokes (the latter of which are almost impossible to translate, which is why the comics are at their best in their original language).<br /><br />Both are quite hard to capture in film, which is why those will never be as good as the comics. Movies are simply a different medium than comics. With that in mind, this movie does surprisingly well in capturing the fun of the comic.<br /><br />The word gags are bearable, and sometimes even funny (Debouze does an Amelie reference!). I have to mention that I watched the french version. If you don't watch the french version or your lack of understanding of the french language limits you to the subtitles, the word jokes will probably suck.<br /><br />The slapstick is okay as well; it's a very simple form of humor, and not really funny when you're older than twelve, but it captures the spirit of the comicbooks. The other visual jokes are the movie's saving grace for the older audience, as their often quite funny.<br /><br />The acting is totally over the top, but again, that's not annoying at all as it captures the spirit of the comicbooks. Only Depardieu and Clavier don't really overact, which might be the reason some people think they didn't enjoy their roles (I didn't notice a thing). On the other hand Jamel Debouze and especially Claude Rich turn overacting into an artform. It's actually fun to watch. Again, I fear it wouldn't be nearly as funny when the voices are dubbed.<br /><br />Overall not a bad movie at all, much better than the previous one. It's not a classic and it doesn't dethrone The Twelve Tasks of Asterix as my favourite Asterix movie, but it's still worth seeing. The french version, that is. 7/10\n",
      "\n",
      "Labeled sentiment: positive\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.78     0.13     0.08    0.05\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "Komodo vs. Cobra starts as 'One Planet' environmentalist Jerry Ryan (Ryan McTavish) & his girlfriend Carrie (Renee Talbert) hire Captain Michael Stoddard (executive producer Michael Paré) to take them to an island in the South Pacific, at first Stoddard is reluctant since the island is a top secret military research base but soon changes his mind when a load of cash is offered. Along with TV news reporter Sandra Crescent (Jeri Manthey) they set sail for the island & once ashore find out that the military have been funding illegal DNA genetic experiments which have resulted in huge Komodo Dragon's & King Cobra's that have eaten almost every other living thing there & Stoddard & co are next on the menu...<br /><br />Co-written & directed by the ever awful Jim Wynorski under his Jay Andrews pseudonym this is just plain awful, this is just plain hard to sit through & is even worse than the usual rubbish 'Creature Features' the Sci-Fi Channel have the nerve to air if that's possible. The script is terrible, predictable & utterly boring, some giant monsters of some sort are created by scientists messing around with DNA, a group of people are trapped with said monsters & have to try to escape being eaten. That's it, that's the whole plot of Komodo vs. Cobra, maybe this was trying to rip-off AVP: Alien vs. Predator (2004) with the title but all the 'vs.' bit amounts to is a rubbish thirty second stand-off between the two titular beasts at the very end, boring as hell & surely a big disappointment to anyone hoping to have a full on monster mash. The character's are poor, the dialogue is awful, the pace is slow, the story is predictable & cliché ridden & the whole film just sucks really with a lazy script that states wrongly that both Komodo Dragon's & Cobra's are amphibious which they are not. Hell, Komodo vs. Cobra isn't even worth watching for any unintentional laughs since it's so dull & hardly anything ever happens although the sight of a woman hiding behind the smallest rock on the beach from the Cobra is quite funny for the wrong reasons.<br /><br />How does Wynorski keep getting directing jobs? He is probably consistently the worst director currently working, how can he keep getting fun sounding films set on beautiful locations with half decent casts & still churn out such an awful film? I think this was cut to get a PG or for it's TV showing since every time someone swears it's masked by a Parrot squeak! There's zero gore or violence & the monster scenes are limp, people just sort of stand there, the monsters just sort of stands there too hissing or roaring & that's about it. The CGI computer effects are terrible, this is really poor stuff that just looks horrible.<br /><br />With a supposed budget of about $450,000 this looks as cheap as it was, the Hawaiian locations are nice to look at but that's about it. The acting is poor from an uninterested looking cast.<br /><br />Komodo vs. Cobra is an absolutely terrible Sci-Fi Channel 'Creature Feature' from Jim Wynorski, films don't get much worse than this.\n",
      "\n",
      "Labeled sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            negative        0.84     0.07     0.09   -0.02\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I watch them all.<br /><br />It's not better than the amazing ones (_Strictly Ballroom_, _Shall we dance?_ (Japanese version), but it's completely respectable and pleasingly different in parts.<br /><br />I am an English teacher and I find some of the ignorance about language in some of these reviews rather upsetting. For example: the \"name should scream don't watch. 'How she move.' Since when can movie titles ignore grammar?\" <br /><br />There is nothing inherently incorrect about Caribbean English grammar. It's just not Canadian standard English grammar. Comments about the dialogue seem off to me. I put on the subtitles because I'm a Canadian standard English speaker, so I just AUTOMATICALLY assumed that I would have trouble understanding all of it. It wasn't all that difficult and it gave a distinctly different flavour as the other step movies I have seen were so American.<br /><br />I loved that this movie was set in Toronto and, in fact, wish it was even more clearly set there. I loved that the heroine was so atypically cast. I enjoyed the stepping routines. I liked the driven Mum character. I felt that many of the issues in the movie were addressed more subtly than is characteristic of dance movies.<br /><br />In summary, if you tend to like dance movies, then this is a decent one. If you have superiority issues about the grammar of the English standard you grew up speaking, your narrow mind may have difficulty enjoying this movie.\n",
      "\n",
      "Labeled sentiment: positive\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.82     0.12     0.06    0.06\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I got encouraged to watch this film because I've heard good word of it: it was supposed to be this thrilling true crime milestone, disturbing, shocking... all that jazz. Well, I am disturbed because I spent money on it, and I am shocked that something so God-awful actually got released. That's about it.<br /><br />This is a supposed \"new look\" at Charles Manson's family of insane loser junkies and their murders. But if this is a \"new look\" then it's probably \"new\" as in \"fresh and totally inept\": just watching it gave me a headache and I had to give up trying to make any sense of it or even understand just what the director intended it to be.<br /><br />I suppose I should say something about the plot but fact is, it was so stupid and incoherent that I barely remember if there even WAS a plot at all. There was something about a \"Manson tape\" delivered to a radio DJ (or a TV producer?), then an hour of pointless random footage of \"the family\" in '69, then the Polanski murders (looking like a bad school play) and finally some idiotic part about a bunch of skinheads getting drunk and beating the hell out of one another in an alley (I kid you not), and then it ended (thank God) (Don't ask me to make any sense of that, I'm just recalling what I saw!) The performances were terrible, too. And how difficult is it to make a convincing \"Manson\"? Get a short skinny scrawny bloke, put a dirty wig and a shaggy beard on him. There's your Manson. But this \"Manson\" doesn't even look right. He just looks like, uh, a bloke in a cheap wig and a glued on Santa beard painted black.<br /><br />Or maybe that's what this film is actually about: Manson's family didn't make any sense, so this film doesn't make any sense, either. It's symbolic! (Yeah, right) I'm still so angry at spending money on this I stopped my normal lurking on this site and registered just to vote 1 for this film and post this warning that will hopefully prevent others from spending their money on this garbage. Stay away from it, it's not even worth renting.<br /><br />PS. The recent US TV production \"Helter Skelter\" got bad reviews here but I saw it last month (I saw the 1976 original too) and let me tell you, compared to \"Manson Family\", that new Helter Skelter is BRILLIANT and FLAWLESS. And I was disappointed in it! That's how bad \"Manson Family\" is: it makes a flawed and mostly disappointing TV movie look perfect.\n",
      "\n",
      "Labeled sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.85     0.08     0.07    0.01\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "This movie tries to run away to the typical 'I'm fighting because I'm obliged to defend the fatherland. The NAZI's are all bad guys, I'm against them' (typical of German war movies). How? By not talking too much about it, and just referring the war and the POW's. Nevertheless I would like to see a German movie which would be something between the extremity of Come And See and the \"bad NAZI's\" Das Boot. I say this because, excluding this factor, the German movies are the best depicting 2nd world war and the German side. You easily see some of the German hierarchical relations, very different from the ones in US army.<br /><br />This is a movie which tries to get a real sight of what was Stalingrad, and I was not there, and I doubt most people were there now, but if I would choose one movie depicting this battle, for sure would not be the all American Enemy At The Gates. Why do I say this? Because even the best soldiers are not hero's, and given the conditions they may regard their own lives instead of the fatherland. This goes for all the ranks, and in the end you see von Paulus giving the example.\n",
      "\n",
      "Labeled sentiment: positive\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            negative        0.88     0.06     0.06     0.0\n",
      "------------------------------------------------------------\n",
      "Review:\n",
      "I haven't had a chance to view the previous film, but from what I've read on other posts it was supposedly worse than this one, although I doubt that is possible. I'm a huge fan of the \"Zombie\" genre, and I am fascinated by the psychological aspects of viewing creatures, that for all intents and purposes are human, as an atrocity that is only worth shooting in the head. That said, HOTD 2 takes the \"Zombie\" movie to an all new low.<br /><br />Without giving any big spoilers (which I really should do just so you won't bother wasting your time actually watching this movie) I would like to express my utter contempt for the way the writers of this film portray our countries Special Forces. Gomer Pile could have probably survived longer than the \"Spec Ops\" soldiers in this film. For crying out loud they should have called them the Special Education Forces instead. If you are going to write a script where you send in an elite team to deal with an outbreak of zombies, at least have the soldiers be smarter than the walking corpses. I understand that you have to kill off some or most of the team, but you can find better ways to do it than having them set down their machine guns and walk over to lay a tender hand on the shoulder of the drooling crazy person rocking back and forth in the corner of the dark creepy basement.<br /><br />The writers actually try to take the whole zombie thing to a more high-tech level by making it a virus that they are searching for a vaccine for, and the idea has merit, if it wasn't stuck in the middle of such a ridiculous display of wayward film making. I mean come on, zombie films aren't exactly \"high art\", and the viewer expects some tongue-in-cheek cheesiness along with the gore and thrills, but HOTD 2 is the type of cheese that makes you turn the channel in disgust and awe of the sheer stupidity of the characters. If you are a zombie movie fan like me, please do yourself a favor and stay away from this one.\n",
      "\n",
      "Labeled sentiment: negative\n",
      "\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.83      0.1     0.07    0.04\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for review, review_sentiment in sample_data:\n",
    "    print('Review:')\n",
    "    print(review)\n",
    "    print()\n",
    "    print('Labeled sentiment:', review_sentiment)\n",
    "    print()\n",
    "    final_sentiment = analyze_sentiment_sentiwordnet_lexicon(review, verbose=True)\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.59\n",
      "Recall: 0.86\n",
      "F1 Score: 0.7\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive        433       71\n",
      "        negative        306      190\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.59      0.86      0.70       504\n",
      "    negative       0.73      0.38      0.50       496\n",
      "\n",
      "    accuracy                           0.62      1000\n",
      "   macro avg       0.66      0.62      0.60      1000\n",
      "weighted avg       0.66      0.62      0.60      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict sentiment for test movie reviews dataset.\n",
    "sentiwordnet_predictions = [analyze_sentiment_sentiwordnet_lexicon(review)\n",
    "                            for review in test_reviews]\n",
    "\n",
    "# Get model performance statistics.\n",
    "print('Performance metrics:')\n",
    "display_evaluation_metrics(true_labels=test_sentiments,\n",
    "                           predicted_labels=sentiwordnet_predictions,\n",
    "                           positive_class='positive')\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "display_confusion_matrix(true_labels=test_sentiments,\n",
    "                         predicted_labels=sentiwordnet_predictions,\n",
    "                         classes=['positive', 'negative'])\n",
    "\n",
    "print()\n",
    "print('Classification Report:')\n",
    "display_classification_report(true_labels=test_sentiments,\n",
    "                              predicted_labels=sentiwordnet_predictions,\n",
    "                              classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VADER Lexicon\n",
    "\n",
    "VADER stands for Valence Aware Dictionary and sEntiment Reasoner. It is a lexicon with a rule-based sentiment analysis framework that was specially built for analyzing sentiment from social media resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def analyze_sentiment_vader_lexicon(review,\n",
    "                                    threhold=0.1,\n",
    "                                    verbose=False):\n",
    "    # Pre-process text.\n",
    "    review = normalize_accented_characters(review)\n",
    "    review = html.unescape(review.decode('utf-8'))\n",
    "    review = strip_html(review)\n",
    "    \n",
    "    # Analyze the sentiment for review.\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    \n",
    "    # Get aggregate scores and final sentiment.\n",
    "    agg_score = scores['compound']\n",
    "    \n",
    "    final_sentiment = 'positive' if agg_score >= threshold else 'negative'\n",
    "    \n",
    "    if verbose:\n",
    "        # Display detailed sentiment statistics.\n",
    "        positive = str(round(scores['pos'], 2) * 100) + '%'\n",
    "        final = round(agg_score, 2)\n",
    "        negative = str(round(scores['neg'], 2) * 100) + '%'\n",
    "        neutral = str(round(scores['neu'], 2) * 100) + '%'\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive, negative, neutral]],\n",
    "                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'],\n",
    "                                                                     ['Predicted Sentiment',\n",
    "                                                                      'Polarity Score',\n",
    "                                                                      'Positive',\n",
    "                                                                      'Negative',\n",
    "                                                                      'Neutral']],\n",
    "                                                            labels=[[0, 0, 0, 0, 0], [0, 1, 2, 3, 4]]))\n",
    "        print(sentiment_frame)\n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "I watch them all.<br /><br />It's not better than the amazing ones (_Strictly Ballroom_, _Shall we dance?_ (Japanese version), but it's completely respectable and pleasingly different in parts.<br /><br />I am an English teacher and I find some of the ignorance about language in some of these reviews rather upsetting. For example: the \"name should scream don't watch. 'How she move.' Since when can movie titles ignore grammar?\" <br /><br />There is nothing inherently incorrect about Caribbean English grammar. It's just not Canadian standard English grammar. Comments about the dialogue seem off to me. I put on the subtitles because I'm a Canadian standard English speaker, so I just AUTOMATICALLY assumed that I would have trouble understanding all of it. It wasn't all that difficult and it gave a distinctly different flavour as the other step movies I have seen were so American.<br /><br />I loved that this movie was set in Toronto and, in fact, wish it was even more clearly set there. I loved that the heroine was so atypically cast. I enjoyed the stepping routines. I liked the driven Mum character. I felt that many of the issues in the movie were addressed more subtly than is characteristic of dance movies.<br /><br />In summary, if you tend to like dance movies, then this is a decent one. If you have superiority issues about the grammar of the English standard you grew up speaking, your narrow mind may have difficulty enjoying this movie.\n",
      "\n",
      "Labeled Sentiment: positive\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "analyze_sentiment_vader_lexicon() got an unexpected keyword argument 'threshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-53f8933142e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     final_sentiment = analyze_sentiment_vader_lexicon(review,\n\u001b[1;32m      9\u001b[0m                                                       \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                                       verbose=True)\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: analyze_sentiment_vader_lexicon() got an unexpected keyword argument 'threshold'"
     ]
    }
   ],
   "source": [
    "# Get detailed sentiment statistics.\n",
    "for review, review_sentiment in sample_data:\n",
    "    print('Review:')\n",
    "    print(review)\n",
    "    print()\n",
    "    print('Labeled Sentiment:', review_sentiment)\n",
    "    print()\n",
    "    final_sentiment = analyze_sentiment_vader_lexicon(review,\n",
    "                                                      threshold=0.1,\n",
    "                                                      verbose=True)\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_predictions = [analyze_sentiment_vader_lexicon(review, threshold=0.1)\n",
    "                     for review in test_reviews]\n",
    "\n",
    "# Get model performance statistics.\n",
    "print('Performance metrics:')\n",
    "display_evaluation_metrics(true_labels=test_sentiments,\n",
    "                           predicted_labels=vader_predictions,\n",
    "                           positive_class='positive')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "display_confusion_matrix(true_labels=test_sentiments,\n",
    "                         predicted_labels=vader_predictions,\n",
    "                         classes=['positive', 'negative'])\n",
    "\n",
    "print('\\Classification report:')\n",
    "display_classfication_report(true_labels=test_sentiments,\n",
    "                             predicted_labels=vader_predictions,\n",
    "                             classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import sentiment, mood, modality\n",
    "\n",
    "def analyze_sentiment_pattern_lexicon(review, threshold=0.1, verbose=False):\n",
    "    # Pre-process text.\n",
    "    review = normalize_accented_characters(review)\n",
    "    review = html.unescape(review.decode('utf-8'))\n",
    "    review = strip_html(review)\n",
    "    \n",
    "    # Analyze sentiment for the text document.\n",
    "    analysis = sentiment(review)\n",
    "    sentiment_score = round(analysis[0], 2)\n",
    "    sentiment_subjectivity = round(analysis[1], 2)\n",
    "    \n",
    "    # Get final sentiment.\n",
    "    final_sentiment = 'positive' if sentiment_score >= threshold else 'negative'\n",
    "    if verbose:\n",
    "        # Display detailed sentiment statistics.\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, sentiment_score, sentiment_subjectivity]],\n",
    "                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'],\n",
    "                                                                     ['Predicted Sentiment',\n",
    "                                                                      'Polarity Score',\n",
    "                                                                      'Subjectivity Score']],\n",
    "                                                             labels=[[0, 0, 0], [0, 1, 2]]))\n",
    "        print(sentiment_frame)\n",
    "        assessment = analysis.assessments\n",
    "        assessment_frame = pd.DataFrame(assessment,\n",
    "                                        columns=pd.MultiIndex(levels=[['DETAILED ASSESSMENT STATS:'],\n",
    "                                                                      ['Key Terms', 'Polarity Score',\n",
    "                                                                       'Subjectivity Score', 'Type']],\n",
    "                                                              labels=[[0, 0, 0, 0], [0,1,2,3]]))\n",
    "        print(assessment_frame)\n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed sentiment statistics.\n",
    "for review, review_sentiment in sample_data:\n",
    "    print('Review:')\n",
    "    print(review)\n",
    "    print()\n",
    "    print('Labeled sentiment:', review_sentiment)\n",
    "    print()\n",
    "    final_sentiment = analyze_sentiment_pattern_lexicon(review, threshold=0.1, verbose=True)\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review, review_sentiment in sample_data:\n",
    "    print('Review:')\n",
    "    print(review)\n",
    "    print('Labeled sentiment:', review_sentiment)\n",
    "    print('Mood:', mood(review))\n",
    "    mod_score = modality(review)\n",
    "    print('Modality score:', round(mod_score, 2))\n",
    "    print('Certainty: ', 'Strong' if mod_score > 0.5 else 'Medium' if mod_score > 0.35 else 'Low')\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiment for test movie reviews dataset.\n",
    "pattern_predictions = [analyze_sentiment_pattern_lexicon(review, threshold=0.1) for review in test_reviews]\n",
    "\n",
    "# Get model performance statistics.\n",
    "print('Performance statistics:')\n",
    "display_evaluation_metrics(true_labels=test_sentiments,\n",
    "                           predicted_labels=pattern_predictions,\n",
    "                           positive_class='positive')\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "display_confusion_matrix(true_labels=test_sentiments,\n",
    "                         predicted_labels=pattern_predictions,\n",
    "                         classes=['positive', 'negative'])\n",
    "\n",
    "print('\\nClassification report:')\n",
    "display_classification_report(true_labels=test_sentiments,\n",
    "                              predicted_labels=pattern_predictions,\n",
    "                              classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
