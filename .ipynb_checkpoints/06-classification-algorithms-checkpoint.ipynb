{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating classification models\n",
    "\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = ['spam', 'ham', 'spam', 'spam', 'spam',\n",
    "                 'ham', 'ham', 'spam', 'ham', 'spam',\n",
    "                 'spam', 'ham', 'ham', 'ham', 'spam',\n",
    "                 'ham', 'ham', 'spam', 'spam', 'ham']\n",
    "\n",
    "predicted_labels = ['spam', 'spam', 'spam', 'ham', 'spam',\n",
    "                    'spam', 'ham', 'ham', 'spam', 'spam',\n",
    "                    'ham', 'ham', 'spam', 'ham', 'ham',\n",
    "                    'ham', 'spam', 'ham', 'spam', 'spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = Counter(actual_labels)\n",
    "pc = Counter(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spam', 10), ('ham', 10)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spam', 11), ('ham', 9)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_true=actual_labels,\n",
    "                              y_pred=predicted_labels,\n",
    "                              labels=['spam', 'ham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Predicted:</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual:</th>\n",
       "      <th>spam</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted:    \n",
       "                   spam ham\n",
       "Actual: spam          5   5\n",
       "        ham           6   4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=cm, \n",
    "             columns=pd.MultiIndex(levels=[['Predicted:'],\n",
    "                                           ['spam', 'ham']],\n",
    "                                   codes=[[0, 0], [0, 1]]),\n",
    "             index=pd.MultiIndex(levels=[['Actual:'],\n",
    "                                         ['spam', 'ham']],\n",
    "                                 codes=[[0, 0], [0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_class = 'spam'\n",
    "true_positive = 5.\n",
    "false_positive = 6.\n",
    "false_negative = 5.\n",
    "true_negative = 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "The overall accuracy of proportion of correct predictions of the model, which can be depicted by the formula:\n",
    "    \n",
    "$Accuracy = \\frac{TP + TN}{TP + FP + FN + TN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n",
      "Manually computed accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.round(metrics.accuracy_score(y_true=actual_labels,\n",
    "                                           y_pred=predicted_labels), 2)\n",
    "num = true_positive + true_negative\n",
    "den = true_positive + true_negative + false_negative + false_positive\n",
    "accuracy_manual = np.round(num/den, 2)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Manually computed accuracy: {accuracy_manual}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision\n",
    "\n",
    "The number of predictions made that are actually correct or relevant out of all the predictions based on the positive class. This is also known as positive predictive value and can be depicted by the formula.\n",
    "\n",
    "$Precision = \\frac{TP}{TP + FP}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.45\n",
      "Precision Manual: 0.45\n"
     ]
    }
   ],
   "source": [
    "precision = np.round(metrics.precision_score(y_true=actual_labels,\n",
    "                                             y_pred=predicted_labels,\n",
    "                                             pos_label=positive_class), 2)\n",
    "\n",
    "num = true_positive\n",
    "den = true_positive + false_positive\n",
    "precision_manual = np.round(num/den, 2)\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Precision Manual: {precision_manual}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall\n",
    "\n",
    "Recall is defined as the number of instances of positive class that were correctly predicted. This is also known as hit rate, coverage, sensitivity, and can be depicted by the formula:\n",
    "    \n",
    "$Recall = \\frac{TP}{TP + FN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5\n",
      "Recall Manual: 0.5\n"
     ]
    }
   ],
   "source": [
    "recall = np.round(metrics.recall_score(y_true=actual_labels,\n",
    "                                       y_pred=predicted_labels,\n",
    "                                       pos_label=positive_class), 2)\n",
    "num = true_positive\n",
    "den = true_positive + false_negative\n",
    "recall_manual = np.round(num/den, 2)\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Recall Manual: {recall_manual}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score\n",
    "\n",
    "Another accuracy measure that is computed by taking the harmonic mean of the precision and recall and can be represented as follows:\n",
    "    \n",
    "$F1 Score = \\frac{2 x Precision x Recall}{Precision + Recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.48\n",
      "Manually computed F1 Score: 0.47\n"
     ]
    }
   ],
   "source": [
    "f1_score = np.round(metrics.f1_score(y_true=actual_labels, \n",
    "                                     y_pred=predicted_labels,\n",
    "                                     pos_label=positive_class), 2)\n",
    "num = 2 * precision * recall \n",
    "den = precision + recall\n",
    "f1_score_manual = np.round(num/den, 2)\n",
    "\n",
    "print(f'F1 Score: {f1_score}')\n",
    "print(f'Manually computed F1 Score: {f1_score_manual}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a multi-class classification system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data = fetch_20newsgroups(subset='all',\n",
    "                              shuffle=True,\n",
    "                              remove=('headers', 'footers', 'quotes'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(corpus, labels, test_data_proportions=0.3):\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(corpus, labels, test_size=0.33, random_state=42)\n",
    "    return train_X, test_X, train_Y, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_docs(corpus, labels):\n",
    "    filtered_corpus = []\n",
    "    filtered_labels = []\n",
    "    \n",
    "    for doc, label in zip(corpus, labels):\n",
    "        if doc.strip():\n",
    "            filtered_corpus.append(doc)\n",
    "            filtered_labels.append(label)\n",
    "\n",
    "    return filtered_corpus, filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data.\n",
    "dataset = get_data()\n",
    "\n",
    "# Print all the classes.\n",
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get corpus of documents and their corresponding labels.\n",
    "corpus, labels = dataset.data, dataset.target\n",
    "corpus, labels = remove_empty_docs(corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document: the blood of the lamb.\n",
      "\n",
      "This will be a hard task, because most cultures used most animals\n",
      "for blood sacrifices. It has to be something related to our current\n",
      "post-modernism state. Hmm, what about used computers?\n",
      "\n",
      "Cheers,\n",
      "Kent\n",
      "Class label: 19\n",
      "Actual class label: talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "# See sample document and its label index, name.\n",
    "print(f'Sample document: {corpus[10]}')\n",
    "print(f'Class label: {labels[10]}')\n",
    "print(f'Actual class label: {dataset.target_names[labels[10]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and train datasets.\n",
    "train_corpus, test_corpus, train_labels, test_labels = prepare_datasets(corpus, labels, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.normalization import normalize_corpus\n",
    "\n",
    "norm_train_corpus = normalize_corpus(train_corpus)\n",
    "norm_test_corpus = normalize_corpus(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.feature_extractors import bow_extractor, tfidf_extractor\n",
    "from module.feature_extractors import averaged_word_vectorizer\n",
    "from module.feature_extractors import tfidf_weighted_averaged_word_vectorizer\n",
    "\n",
    "import nltk\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words features.\n",
    "bow_vectorizer, bow_train_features = bow_extractor(norm_train_corpus)\n",
    "bow_test_features = bow_vectorizer.transform(norm_test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tfidf features.\n",
    "tfidf_vectorizer, tfidf_train_features = tfidf_extractor(norm_train_corpus)\n",
    "tfidf_test_features = tfidf_vectorizer.transform(norm_test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenized documents.\n",
    "tokenized_train = [nltk.word_tokenize(text)\n",
    "                   for text in norm_train_corpus]\n",
    "tokenized_test = [nltk.word_tokenize(text)\n",
    "                  for text in norm_test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build word2vec model.\n",
    "model = gensim.models.Word2Vec(tokenized_train,\n",
    "                               size=500,\n",
    "                               window=100,\n",
    "                               min_count=30,\n",
    "                               sample=1e-3)\n",
    "\n",
    "# Averaged word vector features.\n",
    "avg_wv_train_features = averaged_word_vectorizer(corpus=tokenized_train,\n",
    "                                                 model=model,\n",
    "                                                 num_features=500)\n",
    "avg_wv_test_features = averaged_word_vectorizer(corpus=tokenized_test,\n",
    "                                                model=model,\n",
    "                                                num_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_weighted_averaged_word_vectorizerraged_word_vectorizereraged_word_vectorizererage_word_vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-ef6cf8370cce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                   num_features=500)\n\u001b[0;32m----> 8\u001b[0;31m tfidf_wv_test_features = tfidf_weighted_averaged_word_vectorizerraged_word_vectorizereraged_word_vectorizererage_word_vectorizer(corpus=tokenized_test,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                                                 \u001b[0mtfidf_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfidf_test_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                                 \u001b[0mtfidf_vocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfidf_weighted_averaged_word_vectorizerraged_word_vectorizereraged_word_vectorizererage_word_vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Tfidf weighted average word vector features.\n",
    "vocab = tfidf_vectorizer.vocabulary_\n",
    "tfidf_wv_train_features = tfidf_weighted_averaged_word_vectorizer(corpus=tokenized_train,\n",
    "                                                                  tfidf_vectors=tfidf_train_features,\n",
    "                                                                  tfidf_vocabulary=vocab,\n",
    "                                                                  model=model,\n",
    "                                                                  num_features=500)\n",
    "tfidf_wv_test_features = tfidf_weighted_averaged_word_vectorizerraged_word_vectorizereraged_word_vectorizererage_word_vectorizer(corpus=tokenized_test,\n",
    "                                                                tfidf_vectors=tfidf_test_features,\n",
    "                                                                tfidf_vocabulary=vocab,\n",
    "                                                                model=model,\n",
    "                                                                num_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    print('Accuracy:', np.round(metrics.accuracy_score(true_labels, predicted_labels), 2))\n",
    "    print('Precision:', np.round(metrics.precision_score(true_labels, predicted_labels, average='weighted'), 2))\n",
    "    print('Recall:', np.round(metrics.recall_score(true_labels, predicted_labels, average='weighted'), 2))\n",
    "    print('F1 Score:', np.round(metrics.f1_score(true_labels, predicted_labels, average='weighted'), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_evaluate_model(classifier, \n",
    "                                 train_features, train_labels,\n",
    "                                 test_features, test_labels):\n",
    "    # Build model.\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    \n",
    "    # Predict using model.\n",
    "    predictions = classifier.predict(test_features)\n",
    "    \n",
    "    # Evaluate model prediction performance.\n",
    "    get_metrics(true_labels=test_labels, \n",
    "                predicted_labels=predictions)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "svm = SGDClassifier(loss='hinge', max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "Precision: 0.72\n",
      "Recall: 0.67\n",
      "F1 Score: 0.65\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Niave Bayes with bag of word features.\n",
    "mnb_bow_predictions = train_predict_evaluate_model(classifier=mnb,\n",
    "                                                   train_features=bow_train_features,\n",
    "                                                   train_labels=train_labels,\n",
    "                                                   test_features=bow_test_features,\n",
    "                                                   test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63\n",
      "Precision: 0.68\n",
      "Recall: 0.63\n",
      "F1 Score: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines with bag of word features.\n",
    "svm_bow_predictions = train_predict_evaluate_model(classifier=svm, \n",
    "                                                   train_features=bow_train_features,\n",
    "                                                   train_labels=train_labels,\n",
    "                                                   test_features=bow_test_features,\n",
    "                                                   test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "Precision: 0.78\n",
      "Recall: 0.72\n",
      "F1 Score: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes with tfidf features.\n",
    "mnb_tfidf_predictions = train_predict_evaluate_model(classifier=mnb,\n",
    "                                                     train_features=tfidf_train_features,\n",
    "                                                     train_labels=train_labels,\n",
    "                                                     test_features=tfidf_test_features,\n",
    "                                                     test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "Precision: 0.77\n",
      "Recall: 0.77\n",
      "F1 Score: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines with tfidf features.\n",
    "svm_tfidf_predictions = train_predict_evaluate_model(classifier=svm,\n",
    "                                                     train_features=tfidf_train_features,\n",
    "                                                     train_labels=train_labels,\n",
    "                                                     test_features=tfidf_test_features,\n",
    "                                                     test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53\n",
      "Precision: 0.55\n",
      "Recall: 0.53\n",
      "F1 Score: 0.51\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines with averaged word vector features.\n",
    "svm_avgwv_predictions = train_predict_evaluate_model(classifier=svm,\n",
    "                                                     train_features=avg_wv_train_features,\n",
    "                                                     train_labels=train_labels,\n",
    "                                                     test_features=avg_wv_test_features,\n",
    "                                                     test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines with tfidf averaged word vector features.\n",
    "svm_avgwv_predictions = train_predict_evaluate_model(classifier=svm,\n",
    "                                                     train_features=tfidf_wv_train_features,\n",
    "                                                     train_labels=train_labels,\n",
    "                                                     test_features=tfidf_wv_test_features,\n",
    "                                                     test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>220</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>220</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>229</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>268</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>247</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>255</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>279</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>259</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>210</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>268</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>261</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>293</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>227</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>260</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>163</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
       "0   157    3    0    1    1    0    2    3    4    1    5    4    1    4    5   \n",
       "1     1  225    9    7    8   14    8    1    2    1    0    2    5    2    6   \n",
       "2     1   21  220   18   10   18    7    1    0    0    0    2    7    1    2   \n",
       "3     1   12   25  220   11    4    8    3    1    1    1    2    6    2    1   \n",
       "4     1    4    6   14  229    6    4    2    3    1    0    3    9    3    4   \n",
       "5     0   24   18    1    1  269    0    1    1    0    0    0    4    3    1   \n",
       "6     0    2    7   11   12    2  268   11    4    2    1    1   10    1    3   \n",
       "7     1    5    2    2    1    3    4  247   20    1    2    2   10    4    2   \n",
       "8     4    1    0    4    2    2    4   25  255    4    5    2    1    4    1   \n",
       "9     1    1    1    0    2    2    5    3    6  279   11    2    1    1    2   \n",
       "10    0    0    0    0    0    0    1    3    2    4  282    1    2    1    4   \n",
       "11    3    5    4    3    1    2    2    2    2    2    0  259    6    3    0   \n",
       "12    1    7    6   14    8    1   15   10    8    4    4    2  210    5    2   \n",
       "13    2    4    0    1    3    4    3    0    2    1    1    1    6  268    4   \n",
       "14    0    5    3    0    2    4    2    5    6    2    1    0    8    4  261   \n",
       "15   11    1    0    0    1    1    0    0    4    1    3    2    1    7    5   \n",
       "16    4    0    0    0    0    3    2    1    7    3    2   13    1    2    4   \n",
       "17    6    0    1    0    1    1    0    2    3    2    5    6    1    3    1   \n",
       "18   10    1    2    1    1    1    2    2    5    3    2    9    0    8    5   \n",
       "19   21    4    0    1    0    3    2    3    8    2    2    1    0   13    3   \n",
       "\n",
       "     15   16   17   18  19  \n",
       "0    35    3    7    7  20  \n",
       "1     1    3    0    2   0  \n",
       "2     2    1    1    2   0  \n",
       "3     0    1    1    0   0  \n",
       "4     1    1    0    1   0  \n",
       "5     1    0    1    0   0  \n",
       "6     0    2    1    1   0  \n",
       "7     0    3    3    4   0  \n",
       "8     3    1    1    3   0  \n",
       "9     4    2    0    1   1  \n",
       "10    1    0    1    1   0  \n",
       "11    1    4    2    5   0  \n",
       "12    1    1    2    0   1  \n",
       "13    2    3    0    3   0  \n",
       "14    2    4    1    3   1  \n",
       "15  293    3    4    2   4  \n",
       "16    3  227    5   12   2  \n",
       "17    6    5  260    9   3  \n",
       "18    4   33    7  163   3  \n",
       "19   58   19    7    3  63  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cm = metrics.confusion_matrix(test_labels, svm_tfidf_predictions)\n",
    "pd.DataFrame(cm, index=range(0, 20), columns=range(0, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism -> talk.religion.misc\n",
      "talk.politics.misc -> talk.politics.guns\n",
      "talk.religion.misc -> soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "class_names = dataset.target_names\n",
    "print(class_names[0], '->', class_names[19])\n",
    "print(class_names[18], '->', class_names[16])\n",
    "print(class_names[19], '->', class_names[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label: alt.atheism\n",
      "Predicted label: talk.religion.misc\n",
      "Document:-\n",
      " Yup, I think you're right.  My mistake.  Now, how do I make an \"R\" backwards using a computer keyboard?  I'll bet the gods know how (this is alt.atheism, after all).  Tell you what, if all my \"R\"s start coming out backwards when I type from now on, I'll become a believer.  (And that's not asking for miracles.  If I asked for a miracle, I'd ask for a real miracle, like for Pat Buchanan to become an out-of-the-closet drag queen - well...maybe that wouldn't be so miraculous, but I think he'd look fabulous in a feather boa and a sequined hat like Mia Farrow wore in Gatsby.)\n",
      "\n",
      "Actual label: alt.atheism\n",
      "Predicted label: talk.religion.misc\n",
      "Document:-\n",
      " Hehehe, so you say, but this objective morality somehere tells you  that this is not the case, and you don't know all the rules of such transcendental game systems...  Cheers, Kent\n",
      "\n",
      "Actual label: alt.atheism\n",
      "Predicted label: talk.religion.misc\n",
      "Document:-\n",
      "-*----   I believe that Maharishi is titular.  (Someone please correct me if  I am wrong.)  Thus, Maharishi Rajneesh is a different person from Maharishi Mahesh, but they are both Maharishis.\n",
      "\n",
      "Actual label: alt.atheism\n",
      "Predicted label: talk.religion.misc\n",
      "Document:-\n",
      " [rest deleted...]  You were a liberal arts major, weren'tcha?  Guess you never saw that photo of the smallest logo in the world-- \"IBM\" made with noble gas atoms (krypton? xenon? I forget the specifics).  Atoms, trees, electrons are all independently observable and verifiable. Morals aren't. See the difference?  Tep\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "num = 0\n",
    "for document, label, predicted_label in zip(test_corpus, test_labels, svm_tfidf_predictions):\n",
    "    if label == 0 and predicted_label == 19:\n",
    "        print('Actual label:', class_names[label])\n",
    "        print('Predicted label:', class_names[predicted_label])\n",
    "        print('Document:-')\n",
    "        print(re.sub('\\n', ' ', document))\n",
    "        print()\n",
    "        num += 1\n",
    "        if num == 4:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
