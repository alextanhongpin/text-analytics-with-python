{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization\n",
    "\n",
    "What can we do?\n",
    "- extract key influential phrases from the documents\n",
    "- extract various diverse concepts or topics present in the documents\n",
    "- summarize the documents to provide a gists that retains the important parts of the whole corpus\n",
    "\n",
    "\n",
    "## Techniques\n",
    "\n",
    "- keyphrase extraction - extracting keywords or phrases from a text document of corpus that capture its main concepts or themes\n",
    "- topic modelling - using statistical and mathematical modelling techniques to extract main topics, themes or concepts from a corpus of documents.\n",
    "- automated document summarization - process of using a computer program or algorithm based on statistical and ML techniques to summarize a document or corpus of documents such that we obtain a short summary that captures all the essential concepts and themes of the original document or corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "def low_rank_svd(matrix, singular_count=2):\n",
    "    u, s, vt = svds(matrix, k=singular_count)\n",
    "    return u, s, vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_document(document):\n",
    "    '''\n",
    "    Remove newline from document, parse the text, convert it into ASCII format, \n",
    "    and break down into its sentence constituents.\n",
    "    '''\n",
    "    document = re.sub(\"\\n\", ' ', document)\n",
    "    if isinstance(document, str):\n",
    "        document = document\n",
    "    elif isinstance(document, unicode):\n",
    "        return unicodedata.normalize('NFKD', document).encode('ascii', 'ignore')\n",
    "    else:\n",
    "        raise ValueError('Document is not string or unicode!')\n",
    "    document = document.strip()\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [sentence.strip() for sentence in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "def unescape_html(parser, text):\n",
    "    return parser.unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.contractions import expand_contractions\n",
    "from module.lemmatize import lemmatize_text\n",
    "from module.tokenize import tokenize_text\n",
    "from module.normalization import remove_special_characters, remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, lemmatize=True, tokenize=False):\n",
    "    normalized_corpus = []\n",
    "    for text in corpus:\n",
    "        text = html.unescape(text)\n",
    "        text = expand_contractions(text)\n",
    "        if lemmatize:\n",
    "            text = lemmatize_text(text)\n",
    "        else:\n",
    "            text = text.lower()\n",
    "        text = remove_special_characters(text)\n",
    "        text = remove_stopwords(text)\n",
    "        if tokenize:\n",
    "            text = tokenize_text(text)\n",
    "            normalized_corpus.append(text)\n",
    "        else:\n",
    "            normalized_corpus.append(text)\n",
    "\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "- binary term occurence-based features\n",
    "- frequency bag of words-based features\n",
    "- tf-idf weighted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def build_feature_matrix(documents, feature_type='frequency'):\n",
    "    feature_type = feature_type.lower().strip()\n",
    "    \n",
    "    if feature_type == 'binary':\n",
    "        vectorizer = CountVectorizer(binary=True, min_df=1, ngram_range=(1, 1))\n",
    "    elif feature_type == 'frequency':\n",
    "        vectorizer = CountVectorizer(binary=False, min_df=1, ngram_range=(1, 1))\n",
    "    elif feature_type == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1, 1))\n",
    "    else:\n",
    "        raise Exception('Wrong feature type entered. Possible values: \"binary\", \"frequency\", \"tfidf\"')\n",
    "\n",
    "    feature_matrix = vectorizer.fit_transform(documents).astype(float)\n",
    "    return vectorizer, feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyphrase Extraction\n",
    "\n",
    "A.k.a terminology extraction, is defined as the process or technique of extracting key important and relevant terms or phrases from a body of unstructured text such that the core topics or themes of the text document(s) are captured in these key phrases.\n",
    "\n",
    "- semantic web\n",
    "- query-based search engine and crawlers\n",
    "- recommendation systems\n",
    "- tagging systems\n",
    "- document similarity\n",
    "- translation\n",
    "\n",
    "Techniques for keyphrase extraction:\n",
    "- collocations\n",
    "- weighted tag-based phrase extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation\n",
    "\n",
    "A collocation is a sequence or group of words that tend to occur frequently such that this frequency tends to be more than what could be termed as a random chance occurence. \n",
    "\n",
    "Techniques to extract collocations:\n",
    "- n-gram grouping or segmentation approach (construct ngrams out of a corpus, count the frequency of each ngram, and rank them based on their frequency of occurence to get the most frequent n-gram collocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alice adventures wonderland lewis carroll 1865'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "# from module.normalization import normalize_corpus\n",
    "import nltk\n",
    "from operator import itemgetter\n",
    "\n",
    "# Load corpus.\n",
    "alice = gutenberg.sents(fileids='carroll-alice.txt')\n",
    "alice = [' '.join(ts) for ts in alice]\n",
    "norm_alice = list(filter(None, normalize_corpus(alice, lemmatize=False)))\n",
    "\n",
    "# Print first line.\n",
    "norm_alice[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_corpus(corpus):\n",
    "    return ' '.join([document.strip() \n",
    "                     for document in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ngrams(sequence, n):\n",
    "    return zip(*[sequence[index:]\n",
    "                 for index in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (2, 3), (3, 4)]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(compute_ngrams([1,2,3,4], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (2, 3, 4)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(compute_ngrams([1,2,3,4], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_ngrams(corpus, ngram_val=1, limit=5):\n",
    "    corpus = flatten_corpus(corpus)\n",
    "    tokens = nltk.word_tokenize(corpus)\n",
    "    ngrams = compute_ngrams(tokens, ngram_val)\n",
    "    ngrams_freq_dist = nltk.FreqDist(ngrams)\n",
    "    sorted_ngrams_fd = sorted(ngrams_freq_dist.items(),\n",
    "                              key=itemgetter(1),\n",
    "                              reverse=True)\n",
    "    sorted_ngrams = sorted_ngrams_fd[0:limit]\n",
    "    sorted_ngrams = [(' '.join(text), freq)\n",
    "                     for text, freq in sorted_ngrams]\n",
    "    return sorted_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said alice', 123),\n",
       " ('mock turtle', 56),\n",
       " ('march hare', 31),\n",
       " ('said king', 29),\n",
       " ('thought alice', 26),\n",
       " ('white rabbit', 22),\n",
       " ('said hatter', 22),\n",
       " ('said mock', 20),\n",
       " ('said caterpillar', 18),\n",
       " ('said gryphon', 18)]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 10 bigrams.\n",
    "get_top_ngrams(corpus=norm_alice, ngram_val=2, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said mock turtle', 20),\n",
       " ('said march hare', 10),\n",
       " ('poor little thing', 6),\n",
       " ('little golden key', 5),\n",
       " ('certainly said alice', 5),\n",
       " ('white kid gloves', 5),\n",
       " ('march hare said', 5),\n",
       " ('mock turtle said', 5),\n",
       " ('know said alice', 4),\n",
       " ('might well say', 4)]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 10 trigrams.\n",
    "get_top_ngrams(corpus=norm_alice, ngram_val=3, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import BigramAssocMeasures\n",
    "\n",
    "finder = BigramCollocationFinder.from_documents([item.split()\n",
    "                                                 for item\n",
    "                                                 in norm_alice])\n",
    "\n",
    "bigram_measures = BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'alice'),\n",
       " ('mock', 'turtle'),\n",
       " ('march', 'hare'),\n",
       " ('said', 'king'),\n",
       " ('thought', 'alice'),\n",
       " ('said', 'hatter'),\n",
       " ('white', 'rabbit'),\n",
       " ('said', 'mock'),\n",
       " ('said', 'caterpillar'),\n",
       " ('said', 'gryphon')]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw frequencies.\n",
    "finder.nbest(bigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abide', 'figures'),\n",
       " ('acceptance', 'elegant'),\n",
       " ('accounting', 'tastes'),\n",
       " ('accustomed', 'usurpation'),\n",
       " ('act', 'crawling'),\n",
       " ('adjourn', 'immediate'),\n",
       " ('adoption', 'energetic'),\n",
       " ('affair', 'trusts'),\n",
       " ('agony', 'terror'),\n",
       " ('alarmed', 'proposal')]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pointwise mutual information.\n",
    "finder.nbest(bigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigrams.\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.collocations import TrigramAssocMeasures\n",
    "\n",
    "finder = TrigramCollocationFinder.from_documents([item.split()\n",
    "                                                  for item\n",
    "                                                  in norm_alice])\n",
    "\n",
    "trigram_measures = TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'mock', 'turtle'),\n",
       " ('said', 'march', 'hare'),\n",
       " ('poor', 'little', 'thing'),\n",
       " ('little', 'golden', 'key'),\n",
       " ('march', 'hare', 'said'),\n",
       " ('mock', 'turtle', 'said'),\n",
       " ('white', 'kid', 'gloves'),\n",
       " ('beau', 'ootiful', 'soo'),\n",
       " ('certainly', 'said', 'alice'),\n",
       " ('might', 'well', 'say')]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw frequencies.\n",
    "finder.nbest(trigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accustomed', 'usurpation', 'conquest'),\n",
       " ('adjourn', 'immediate', 'adoption'),\n",
       " ('adoption', 'energetic', 'remedies'),\n",
       " ('ancient', 'modern', 'seaography'),\n",
       " ('apple', 'roast', 'turkey'),\n",
       " ('arithmetic', 'ambition', 'distraction'),\n",
       " ('brother', 'latin', 'grammar'),\n",
       " ('canvas', 'bag', 'tied'),\n",
       " ('cherry', 'tart', 'custard'),\n",
       " ('circle', 'exact', 'shape')]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pointwise mutual information.\n",
    "finder.nbest(trigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Tag-Based Phrase Extraction\n",
    "\n",
    "1. extract all noun phrases chunks using shallow parsing\n",
    "2. compute tf-idf weights for each chunk and return the top weighted phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_text = \"\"\"Elephants are mammals of the family Elephantidae and the largest existing land animals. Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant. Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons. The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants. African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs. Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin. The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects. Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging. The large ear flaps assist in maintaining a constant body temperature as well as in communication. The pillar-like legs carry their great weight.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.normalization import stopword_list\n",
    "import itertools\n",
    "import nltk\n",
    "from gensim import corpora, models\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(sentences, grammar = r'NP: {<DT>? <JJ>* <NN.*>+}'):\n",
    "    # Build chunker based on grammar pattern.\n",
    "    all_chunks = []\n",
    "    chunker = nltk.chunk.regexp.RegexpParser(grammar)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # POS tag sentences.\n",
    "        tagged_sents = nltk.pos_tag_sents([nltk.word_tokenize(sentence)])\n",
    "        \n",
    "        # Extract chunks.\n",
    "        chunks = [chunker.parse(tagged_sent)\n",
    "                  for tagged_sent in tagged_sents]\n",
    "        \n",
    "        \n",
    "        # Get word, pos_tag, chunk tag triples.\n",
    "        wtc_sents = [nltk.chunk.tree2conlltags(chunk)\n",
    "                     for chunk in chunks]\n",
    "        \n",
    "        flattened_chunks = list(itertools.chain.from_iterable(wtc_sent for wtc_sent in wtc_sents))\n",
    "        \n",
    "        # Get valid chunks based on tags.\n",
    "        valid_chunks_tagged = [(status, [wtc for wtc in chunk])\n",
    "                               for status, chunk\n",
    "                               in itertools.groupby(flattened_chunks,\n",
    "                                                    lambda word_pos_chunk: word_pos_chunk[2] != 'O')]\n",
    "        \n",
    "        # Append words in each chunk to make phrases.\n",
    "        valid_chunks = [' '.join(word.lower() \n",
    "                                 for word, tag, chunk\n",
    "                                 in wtc_group\n",
    "                                     if word.lower() \n",
    "                                         not in stopword_list)\n",
    "                                for status, wtc_group\n",
    "                                in valid_chunks_tagged \n",
    "                                    if status]\n",
    "        \n",
    "        # Append all valid chunked phrases.\n",
    "        all_chunks.append(valid_chunks)\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elephants are mammals of the family Elephantidae and the largest existing land animals.',\n",
       " 'Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant.',\n",
       " 'Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons.',\n",
       " 'The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants.',\n",
       " 'African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs.',\n",
       " 'Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin.',\n",
       " 'The trunk, also called a proboscis, is used for breathing, bringing food and water to the mouth, and grasping objects.',\n",
       " 'Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging.',\n",
       " 'The large ear flaps assist in maintaining a constant body temperature as well as in communication.',\n",
       " 'The pillar-like legs carry their great weight.']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = parse_document(toy_text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['elephants', 'mammals', 'family elephantidae', 'land animals'],\n",
       " ['species',\n",
       "  'african bush elephant',\n",
       "  'african forest elephant',\n",
       "  'asian elephant'],\n",
       " ['elephantidae',\n",
       "  'family',\n",
       "  'order proboscidea',\n",
       "  'extinct members',\n",
       "  'mastodons'],\n",
       " ['family elephantidae',\n",
       "  'several now-extinct groups',\n",
       "  'mammoths',\n",
       "  'straight-tusked elephants'],\n",
       " ['african elephants',\n",
       "  'ears',\n",
       "  'backs',\n",
       "  'whereas asian elephants',\n",
       "  'ears',\n",
       "  'convex',\n",
       "  'level backs'],\n",
       " ['distinctive features',\n",
       "  'elephants',\n",
       "  'long trunk',\n",
       "  'tusks',\n",
       "  'large ear flaps',\n",
       "  'massive legs',\n",
       "  'sensitive skin'],\n",
       " ['trunk', 'proboscis', 'breathing', 'food', 'water', 'mouth', 'objects'],\n",
       " ['tusks', 'incisor teeth', 'weapons', 'tools', 'objects', 'digging'],\n",
       " ['large ear flaps', 'constant body temperature', 'communication'],\n",
       " ['pillar-like legs', 'great weight']]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print all valid keyphrases per sentence of our document. Since we targetted nouns, all phrases talk about noun based entities.\n",
    "valid_chunks = get_chunks(sentences)\n",
    "valid_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_weighted_keyphrases(sentences, \n",
    "                                  grammar=r'NP: {<DT>? <JJ>* <NN.*>+}',\n",
    "                                  top_n=10):\n",
    "    # Get valid chunks.\n",
    "    valid_chunks = get_chunks(sentences, grammar)\n",
    "    \n",
    "    # Build tf-idf based model.\n",
    "    dictionary = corpora.Dictionary(valid_chunks)\n",
    "    \n",
    "    corpus = [dictionary.doc2bow(chunk) for chunk in valid_chunks]\n",
    "    \n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    \n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    \n",
    "    # Get phrases and their tf-idf weights.\n",
    "    weighted_phrases = {dictionary.get(id): round(value, 3)\n",
    "                        for doc in corpus_tfidf\n",
    "                        for id, value in doc}\n",
    "    weighted_phrases = sorted(weighted_phrases.items(), \n",
    "                              key=itemgetter(1), \n",
    "                              reverse=True)\n",
    "\n",
    "    # Return top weighted phrases.\n",
    "    return weighted_phrases[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great weight', 0.707),\n",
       " ('pillar-like legs', 0.707),\n",
       " ('ears', 0.667),\n",
       " ('communication', 0.634),\n",
       " ('constant body temperature', 0.634),\n",
       " ('land animals', 0.58),\n",
       " ('mammals', 0.58),\n",
       " ('mammoths', 0.535),\n",
       " ('several now-extinct groups', 0.535),\n",
       " ('straight-tusked elephants', 0.535)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tfidf_weighted_keyphrases(sentences, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling\n",
    "\n",
    "The main aim of topic modelling is to use mathematical and statistical techniques to discover hidden and latent semantic structures in a corpus.\n",
    "\n",
    "Techniques:\n",
    "- latent semantic indexing\n",
    "- latent dirichlet allocation\n",
    "- non-negative matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_corpus = [\n",
    "    'The fox jumps over the dog',\n",
    "    'The fox is very clever and quick',\n",
    "    'The dog is slow and lazy',\n",
    "    'The cat is smarter than the fox and the dog',\n",
    "    'Python is an excellent programming language',\n",
    "    'Java and Ruby are other programming languages',\n",
    "    'Python and Java are very popular programming languages',\n",
    "    'Python programs are smaller than Java programs'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent semantic indexing\n",
    "\n",
    "The main principle behind LSI is that similar terms tend to be used in the same context and hence tend to co-occur more. The term LSI comes from the fact that this technique has the ability to uncover latent hidden terms which correlate semantically to form topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['fox', 'jump', 'dog'],\n",
       " ['fox', 'clever', 'quick'],\n",
       " ['dog', 'slow', 'lazy'],\n",
       " ['cat', 'smarter', 'fox', 'dog'],\n",
       " ['python', 'excellent', 'programming', 'language'],\n",
       " ['java', 'ruby', 'programming', 'language'],\n",
       " ['python', 'java', 'popular', 'programming', 'language'],\n",
       " ['python', 'program', 'small', 'java', 'program']]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_tokenized_corpus = normalize_corpus(toy_corpus, tokenize=True)\n",
    "norm_tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': 0,\n",
       " 'fox': 1,\n",
       " 'jump': 2,\n",
       " 'clever': 3,\n",
       " 'quick': 4,\n",
       " 'lazy': 5,\n",
       " 'slow': 6,\n",
       " 'cat': 7,\n",
       " 'smarter': 8,\n",
       " 'excellent': 9,\n",
       " 'language': 10,\n",
       " 'programming': 11,\n",
       " 'python': 12,\n",
       " 'java': 13,\n",
       " 'ruby': 14,\n",
       " 'popular': 15,\n",
       " 'program': 16,\n",
       " 'small': 17}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the dictionary.\n",
    "dictionary = corpora.Dictionary(norm_tokenized_corpus)\n",
    "\n",
    "# View the dictionary mappings.\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(1, 1), (3, 1), (4, 1)],\n",
       " [(0, 1), (5, 1), (6, 1)],\n",
       " [(0, 1), (1, 1), (7, 1), (8, 1)],\n",
       " [(9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(10, 1), (11, 1), (13, 1), (14, 1)],\n",
       " [(10, 1), (11, 1), (12, 1), (13, 1), (15, 1)],\n",
       " [(12, 1), (13, 1), (16, 2), (17, 1)]]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tokenized documents into bag of words vectors.\n",
    "corpus = [dictionary.doc2bow(text)\n",
    "          for text in norm_tokenized_corpus]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tf-idf feature vectors.\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "# Fix the number of topics.\n",
    "total_topics = 2\n",
    "\n",
    "# Build the topic model.\n",
    "lsi = models.LsiModel(corpus_tfidf,\n",
    "                      id2word=dictionary, \n",
    "                      num_topics=total_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1\n",
      "0.459*\"language\" + 0.459*\"programming\" + 0.344*\"python\" + 0.344*\"java\" + 0.336*\"popular\" + 0.318*\"excellent\" + 0.318*\"ruby\" + 0.148*\"program\" + 0.074*\"small\" + 0.000*\"jump\"\n",
      "\n",
      "Topic #2\n",
      "-0.459*\"dog\" + -0.459*\"fox\" + -0.444*\"jump\" + -0.322*\"cat\" + -0.322*\"smarter\" + -0.208*\"lazy\" + -0.208*\"slow\" + -0.208*\"clever\" + -0.208*\"quick\" + 0.000*\"python\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, topic in lsi.print_topics(total_topics):\n",
    "    print(f'Topic #{index+1}')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics_gensim(topic_model, total_topics=1,\n",
    "                        weight_threshold=0.0001,\n",
    "                        display_weights=False,\n",
    "                        num_terms=None):\n",
    "    for index in range(total_topics):\n",
    "        topic = topic_model.show_topic(index)\n",
    "        topic = [(word, round(wt, 2))\n",
    "                 for word, wt in topic\n",
    "                 if abs(wt) >= weight_threshold]\n",
    "        if display_weights:\n",
    "            print(f'Topic #{index+1} with weights')\n",
    "            print(topic[:num_terms] if num_terms else topic)\n",
    "        else:\n",
    "            print(f'Topic #{index+1} without weights')\n",
    "            tw = [term for term, wt in topic]\n",
    "            print(tw[:num_terms] if num_terms else tw)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 without weights\n",
      "['language', 'programming', 'python', 'java', 'popular']\n",
      "\n",
      "Topic #2 without weights\n",
      "['dog', 'fox', 'jump', 'cat', 'smarter']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print topics without weights.\n",
    "print_topics_gensim(topic_model=lsi, \n",
    "                    total_topics=total_topics,\n",
    "                    num_terms=5,\n",
    "                    display_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 with weights\n",
      "[('language', 0.46), ('programming', 0.46), ('python', 0.34), ('java', 0.34), ('popular', 0.34)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('dog', -0.46), ('fox', -0.46), ('jump', -0.44), ('cat', -0.32), ('smarter', -0.32)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print topics with their weights.\n",
    "print_topics_gensim(topic_model=lsi,\n",
    "                    total_topics=total_topics,\n",
    "                    num_terms=5,\n",
    "                    display_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat',\n",
       " 'clever',\n",
       " 'dog',\n",
       " 'excellent',\n",
       " 'fox',\n",
       " 'java',\n",
       " 'jump',\n",
       " 'language',\n",
       " 'lazy',\n",
       " 'popular',\n",
       " 'program',\n",
       " 'programming',\n",
       " 'python',\n",
       " 'quick',\n",
       " 'ruby',\n",
       " 'slow',\n",
       " 'small',\n",
       " 'smarter']"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the term document tf-idf weighted matrix.\n",
    "norm_corpus = normalize_corpus(toy_corpus)\n",
    "vectorizer, tfidf_matrix = build_feature_matrix(norm_corpus, \n",
    "                                                feature_type='tfidf')\n",
    "td_matrix = tfidf_matrix.transpose()\n",
    "td_matrix = td_matrix.multiply(td_matrix > 0)\n",
    "\n",
    "# Fix total topics and get the terms used in the term-document matrix.\n",
    "total_topics = 2\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.36360670e-01,  2.34250774e-01,  7.23707979e-01,\n",
       "         2.07800948e-16,  7.23707979e-01, -1.49500409e-16,\n",
       "         4.30101214e-01,  4.97599298e-17,  2.34250774e-01,\n",
       "        -1.73628522e-16, -1.35455571e-16,  4.97599298e-17,\n",
       "        -2.42669872e-17,  2.34250774e-01,  3.46334914e-17,\n",
       "         2.34250774e-01, -6.77277857e-17,  3.36360670e-01],\n",
       "       [ 6.36127555e-17,  1.74739451e-17,  7.17007834e-17,\n",
       "         3.33482823e-01,  8.67072537e-17,  5.64936227e-01,\n",
       "         3.88084076e-17,  7.29158569e-01, -3.27636470e-18,\n",
       "         3.41283856e-01,  2.12806287e-01,  7.29158569e-01,\n",
       "         5.64936227e-01,  1.74739451e-17,  3.33482823e-01,\n",
       "        -3.27636470e-18,  1.06403144e-01,  6.36127555e-17]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, s, vt = low_rank_svd(td_matrix, singular_count=total_topics)\n",
    "weights = u.transpose() * s[:, None]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topics with their terms and weights.\n",
    "def get_topics_terms_weights(weights, feature_names):\n",
    "    feature_names = np.array(feature_names)\n",
    "    sorted_indices = np.array([list(row[::-1])\n",
    "                               for row\n",
    "                               in np.argsort(np.abs(weights))])\n",
    "    sorted_weights = np.array([list(wt[index])\n",
    "                               for wt, index\n",
    "                               in zip(weights, sorted_indices)])\n",
    "    \n",
    "    sorted_terms = np.array([list(feature_names[row])\n",
    "                             for row \n",
    "                             in sorted_indices])\n",
    "    \n",
    "    topics = [np.vstack((terms.T, term_weights.T)).T\n",
    "              for terms, term_weights\n",
    "              in zip(sorted_terms, sorted_weights)]\n",
    "    \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all topics from a corpus.\n",
    "def print_topics_udf(topics, total_topics=1,\n",
    "                     weight_threshold=0.0001,\n",
    "                     display_weights=False,\n",
    "                     num_terms=None):\n",
    "    for index in range(total_topics):\n",
    "        topic = topics[index]\n",
    "        topic = [(term, float(wt))\n",
    "                 for term, wt in topic]\n",
    "        topic = [(word, round(wt, 2))\n",
    "                 for word, wt in topic\n",
    "                 if abs(wt) >= weight_threshold]\n",
    "        \n",
    "        if display_weights:\n",
    "            print(f'Topic #{index+1} with weights')\n",
    "            print(topic[:num_terms] if num_terms else topic)\n",
    "        else:\n",
    "            print(f'Topic #{index+1} without weights')\n",
    "            tw = [term for term, wt in topic]\n",
    "            print(tw[:num_terms] if num_terms else tw)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 with weights\n",
      "[('fox', 0.72), ('dog', 0.72), ('jump', 0.43), ('smarter', 0.34), ('cat', 0.34), ('quick', 0.23), ('clever', 0.23), ('slow', 0.23), ('lazy', 0.23), ('excellent', 0.0), ('popular', -0.0), ('java', -0.0), ('program', -0.0), ('small', -0.0), ('programming', 0.0), ('language', 0.0), ('ruby', 0.0), ('python', -0.0)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('programming', 0.73), ('language', 0.73), ('java', 0.56), ('python', 0.56), ('popular', 0.34), ('ruby', 0.33), ('excellent', 0.33), ('program', 0.21), ('small', 0.11), ('fox', 0.0), ('dog', 0.0), ('smarter', 0.0), ('cat', 0.0), ('jump', 0.0), ('quick', 0.0), ('clever', 0.0), ('slow', -0.0), ('lazy', -0.0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics, \n",
    "                 total_topics=total_topics,\n",
    "                 weight_threshold=0,\n",
    "                 display_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 with weights\n",
      "[('fox', 0.72), ('dog', 0.72), ('jump', 0.43), ('smarter', 0.34), ('cat', 0.34), ('quick', 0.23), ('clever', 0.23), ('slow', 0.23), ('lazy', 0.23)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('programming', 0.73), ('language', 0.73), ('java', 0.56), ('python', 0.56), ('popular', 0.34), ('ruby', 0.33), ('excellent', 0.33), ('program', 0.21)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying a threshold.\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 weight_threshold=0.15,\n",
    "                 display_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 without weights\n",
      "['fox', 'dog', 'jump', 'smarter', 'cat', 'quick', 'clever', 'slow', 'lazy']\n",
      "\n",
      "Topic #2 without weights\n",
      "['programming', 'language', 'java', 'python', 'popular', 'ruby', 'excellent', 'program']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying a threshold.\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 weight_threshold=0.15,\n",
    "                 display_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modelling framework using lsi.\n",
    "def train_lsi_model_gensim(corpus, total_topics=2):\n",
    "    norm_tokenized_corpus = normalize_corpus(corpus, tokenize=True)\n",
    "    dictionary = corpora.Dictionary(norm_tokenized_corpus)\n",
    "    mapped_corpus = [dictionary.doc2bow(text)\n",
    "                     for text in norm_tokenized_corpus]\n",
    "    tfidf = models.TfidfModel(mapped_corpus)\n",
    "    corpus_tfidf = tfidf[mapped_corpus]\n",
    "    lsi = models.LsiModel(corpus_tfidf,\n",
    "                          id2word=dictionary,\n",
    "                          num_topics=total_topics)\n",
    "    return lsi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation\n",
    "\n",
    "The LDA is a generative probabilistic model where each document is assumed to have a combination of topics similar to a probabilistic latent semantic indexing model - but in this case, the latent topics contain a Dirichlet prior over them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lda_model_gensim(corpus, total_topics=2):\n",
    "    norm_tokenized_corpus = normalize_corpus(corpus, tokenize=True)\n",
    "    dictionary = corpora.Dictionary(norm_tokenized_corpus)\n",
    "    mapped_corpus = [dictionary.doc2bow(text)\n",
    "                     for text in norm_tokenized_corpus]\n",
    "    \n",
    "    tfidf = models.TfidfModel(mapped_corpus)\n",
    "    corpus_tfidf = tfidf[mapped_corpus]\n",
    "    lda = models.LdaModel(corpus_tfidf,\n",
    "                          id2word=dictionary,\n",
    "                          iterations=1_000,\n",
    "                          num_topics=total_topics)\n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 with weights\n",
      "[('language', 0.08), ('dog', 0.07), ('programming', 0.07), ('cat', 0.06), ('smarter', 0.06)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('program', 0.08), ('jump', 0.07), ('fox', 0.07), ('clever', 0.07), ('quick', 0.06)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the function to generate topics on toy corpus.\n",
    "lda_gensim = train_lda_model_gensim(toy_corpus,\n",
    "                                    total_topics=2)\n",
    "print_topics_gensim(topic_model=lda_gensim,\n",
    "                    total_topics=2,\n",
    "                    num_terms=5,\n",
    "                    display_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 with weights\n",
      "[('fox', 1.85), ('dog', 1.54), ('jump', 1.17), ('clever', 1.11), ('quick', 1.11), ('cat', 1.06), ('smarter', 1.05), ('excellent', 0.6)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('programming', 1.73), ('language', 1.73), ('java', 1.61), ('python', 1.58), ('program', 1.29), ('ruby', 1.09), ('slow', 1.08), ('lazy', 1.08)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Get tf-idf based features.\n",
    "norm_corpus = normalize_corpus(toy_corpus)\n",
    "vectorizer, tfidf_matrix = build_feature_matrix(norm_corpus,\n",
    "                                                feature_type='tfidf')\n",
    "\n",
    "# Build LDA model.\n",
    "total_topics = 2\n",
    "lda = LatentDirichletAllocation(n_components=total_topics,\n",
    "                                max_iter=100,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.0,\n",
    "                                random_state=42)\n",
    "lda.fit(tfidf_matrix)\n",
    "\n",
    "# Get terms and their weights.\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "weights = lda.components_\n",
    "\n",
    "# Generate topics from their terms and weights.\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics, total_topics=total_topics,\n",
    "                 num_terms=8,\n",
    "                 display_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-negative matrix factorization.\n",
    "\n",
    "- another matrix decomposition technique similar to SVD, although NNMF operates on non-negative matrices and works well with multivariante data.\n",
    "- given a non-negative matrix V, the objective is to find two non-negative matrix factors W and H such that when they are multiplied, they can approximately reconstruct V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.23457084, 0.        ,\n",
       "        0.40224194, 0.        , 0.55097194, 0.        , 0.24112469,\n",
       "        0.08972922, 0.55097194, 0.40224194, 0.        , 0.23457084,\n",
       "        0.        , 0.02891331, 0.        ],\n",
       "       [0.2551927 , 0.13205393, 0.57307455, 0.        , 0.57307455,\n",
       "        0.        , 0.34627341, 0.        , 0.13205393, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.13205393, 0.        ,\n",
       "        0.13205393, 0.        , 0.2551927 ]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Build tf-idf document-term matrix.\n",
    "norm_corpus = normalize_corpus(toy_corpus)\n",
    "vectorizer, tfidf_matrix = build_feature_matrix(norm_corpus, \n",
    "                                                feature_type='tfidf')\n",
    "\n",
    "# Build topic model.\n",
    "total_topics = 2\n",
    "nmf = NMF(n_components=total_topics,\n",
    "          random_state=42,\n",
    "          alpha=.1,\n",
    "          l1_ratio=.5)\n",
    "nmf.fit(tfidf_matrix)\n",
    "\n",
    "# Get terms and their weights.\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "weights = nmf.components_\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 with weights\n",
      "[('programming', 0.55), ('language', 0.55), ('python', 0.4), ('java', 0.4), ('popular', 0.24), ('ruby', 0.23), ('excellent', 0.23), ('program', 0.09), ('small', 0.03)]\n",
      "\n",
      "Topic #2 with weights\n",
      "[('dog', 0.57), ('fox', 0.57), ('jump', 0.35), ('smarter', 0.26), ('cat', 0.26), ('quick', 0.13), ('slow', 0.13), ('clever', 0.13), ('lazy', 0.13)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 num_terms=None,\n",
    "                 display_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting topics from product reviews\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load reviews\n",
    "CORPUS = pd.read_csv('amazon_skyrim_reviews.csv')\n",
    "CORPUS = np.array(CORPUS['Reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I base the value of a game on the amount of enjoyable gameplay I can get out of it and this one was definitely worth the price!'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View sample reviews.\n",
    "CORPUS[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of topics.\n",
    "total_topics = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 without weights\n",
      "['skyrim', 'like', 'play', 'one', 'quest', 'go', 'get', 'time', 'oblivion', 'good']\n",
      "\n",
      "Topic #2 without weights\n",
      "['recommend', 'love', 'great', 'ever', 'best', 'buy', 'level', 'elder', 'scroll', 'highly']\n",
      "\n",
      "Topic #3 without weights\n",
      "['recommend', 'fun', 'highly', 'love', 'wonderful', 'ever', 'series', 'best', 'definitely', 'fallout']\n",
      "\n",
      "Topic #4 without weights\n",
      "['fun', 'scroll', 'recommend', 'elder', 'highly', 'wonderful', 'best', 'ever', 'graphic', 'series']\n",
      "\n",
      "Topic #5 without weights\n",
      "['fun', 'scroll', 'elder', 'love', 'highly', 'series', 'ever', 'ive', 'always', 'wonderful']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Technique 1: Latent Semantic Indexing.\n",
    "lsi_gensim = train_lsi_model_gensim(CORPUS,\n",
    "                                    total_topics=total_topics)\n",
    "print_topics_gensim(topic_model=lsi_gensim,\n",
    "                    total_topics=total_topics,\n",
    "                    num_terms=10,\n",
    "                    display_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 without weights\n",
      "['fun', 'great', 'play', 'skyrim', 'like', 'graphic', 'oblivion', 'hour', 'ever', 'love']\n",
      "\n",
      "Topic #2 without weights\n",
      "['play', 'buy', 'hour', 'make', 'much', 'get', 'really', 'oblivion', 'go', 'great']\n",
      "\n",
      "Topic #3 without weights\n",
      "['love', 'definitely', 'much', 'like', 'one', 'quest', 'get', 'would', 'fan', 'play']\n",
      "\n",
      "Topic #4 without weights\n",
      "['quest', 'good', 'dragon', 'series', 'time', 'skyrim', 'get', 'favorite', 'best', 'go']\n",
      "\n",
      "Topic #5 without weights\n",
      "['love', 'one', 'best', 'buy', 'son', 'skyrim', 'go', 'get', 'little', 'long']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Technique 2a: Latent Dirichlet Allocation (gensim).\n",
    "lda_gensim = train_lda_model_gensim(CORPUS,\n",
    "                                    total_topics=total_topics)\n",
    "print_topics_gensim(topic_model=lda_gensim,\n",
    "                    total_topics=total_topics,\n",
    "                    num_terms=10,\n",
    "                    display_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 without weights\n",
      "['language', 'programming', 'python', 'java', 'jump', 'excellent', 'ruby', 'popular', 'fox', 'dog']\n",
      "\n",
      "Topic #2 without weights\n",
      "['dog', 'programming', 'small', 'slow', 'smarter', 'jump', 'python', 'java', 'lazy', 'language']\n",
      "\n",
      "Topic #3 without weights\n",
      "['quick', 'clever', 'fox', 'popular', 'java', 'small', 'jump', 'smarter', 'python', 'program']\n",
      "\n",
      "Topic #4 without weights\n",
      "['program', 'slow', 'lazy', 'dog', 'small', 'java', 'python', 'clever', 'fox', 'popular']\n",
      "\n",
      "Topic #5 without weights\n",
      "['cat', 'smarter', 'dog', 'fox', 'popular', 'python', 'clever', 'small', 'language', 'slow']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Technique 2b: Latent Dirichlet Allocation (scikit-learn).\n",
    "norm_corpus = normalize_corpus(CORPUS)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=total_topics,\n",
    "                                max_iter=100,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.0,\n",
    "                                random_state=42)\n",
    "lda.fit(tfidf_matrix)\n",
    "weights = lda.components_\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics, \n",
    "                 total_topics=total_topics,\n",
    "                 num_terms=10,\n",
    "                 display_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, beta_loss='frobenius', init=None, l1_ratio=0.5, max_iter=200,\n",
       "    n_components=5, random_state=42, shuffle=False, solver='cd', tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Technique 3: Non-negative Matrix Factorization.\n",
    "nmf = NMF(n_components=total_topics,\n",
    "          random_state=42,\n",
    "          alpha=.1,\n",
    "          l1_ratio=.5)\n",
    "nmf.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 without weights\n",
      "['programming', 'language', 'java', 'python', 'ruby', 'excellent', 'popular']\n",
      "\n",
      "Topic #2 without weights\n",
      "['dog', 'fox', 'jump', 'smarter', 'cat']\n",
      "\n",
      "Topic #3 without weights\n",
      "['clever', 'quick', 'fox']\n",
      "\n",
      "Topic #4 without weights\n",
      "['program', 'small', 'python', 'java']\n",
      "\n",
      "Topic #5 without weights\n",
      "['lazy', 'slow', 'dog']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "weights = nmf.components_\n",
    "\n",
    "topics = get_topics_terms_weights(weights, feature_names)\n",
    "print_topics_udf(topics=topics,\n",
    "                 total_topics=total_topics,\n",
    "                 num_terms=10,\n",
    "                 display_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated document summarization.\n",
    "\n",
    "- extraction-based techniques. These methods use mathematical and statistical concepts like SVD to extract some key subset of content from the original document such that this subset of content contains the core information and acts as the focal point of the entire document. No new content is generated in this technique - hence the name extraction-based.\n",
    "- abstraction-based techniques. Leverage language semantics to create representations. They also make use of NLG techniques where the machines use knowledge bases and semantic representation to generate text on its own and creates summaries just like a human would write it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import summarize, keywords\n",
    "\n",
    "def text_summarization_gensim(text, summary_ratio=0.5):\n",
    "    summary = summarize(text, split=True, ratio=summary_ratio)\n",
    "    for sentence in summary:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant.\n",
      "Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons.\n",
      "The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants.\n",
      "Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin.\n"
     ]
    }
   ],
   "source": [
    "docs = parse_document(toy_text)\n",
    "text = ' '.join(docs)\n",
    "text_summarization_gensim(text, summary_ratio=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two techniques in extraction-based summarization algorithm.\n",
    "\n",
    "- latent semantic analysis\n",
    "- textrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in document: 10\n"
     ]
    }
   ],
   "source": [
    "# Parse and normalize document.\n",
    "sentences = parse_document(toy_text)\n",
    "norm_sentences = normalize_corpus(sentences, lemmatize=True)\n",
    "\n",
    "# Check total sentences in document.\n",
    "total_sentences = len(norm_sentences)\n",
    "print('Total sentences in document:', total_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Analysis\n",
    "\n",
    "In any document, there exists a latent structure among terms which are related contextually and hence should also be correlated in the same singular space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7 , 4.6 , 3.53, 2.8 , 5.25, 2.31, 3.23, 3.94, 2.65, 0.89])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the number of sentences and topics for summarized document.\n",
    "num_sentences = 3\n",
    "num_topics = 3\n",
    "\n",
    "# Build document term matrix based on bag of words features.\n",
    "vec, dt_matrix = build_feature_matrix(sentences,\n",
    "                                      feature_type='frequency')\n",
    "\n",
    "# Convert to term document matrix.\n",
    "td_matrix = dt_matrix.transpose()\n",
    "td_matrix = td_matrix.multiply(td_matrix > 0)\n",
    "\n",
    "# Get low rank SVD components.\n",
    "u, s, vt = low_rank_svd(td_matrix, singular_count=num_topics)\n",
    "\n",
    "# Remove singular values below the threshold.\n",
    "sv_threshold = 0.5\n",
    "min_sigma_value = max(s) * sv_threshold\n",
    "s[s < min_sigma_value] = 0\n",
    "\n",
    "# Compute salience scores for all sentences in document.\n",
    "salience_scores = np.sqrt(np.dot(np.square(s), np.square(vt)))\n",
    "\n",
    "# Print salience score for each sentence.\n",
    "np.round(salience_scores, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 7])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank sentence based on their salience scores.\n",
    "top_sentence_indices = salience_scores.argsort()[-num_sentences:][::-1]\n",
    "top_sentence_indices.sort()\n",
    "top_sentence_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant.\n",
      "African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs.\n",
      "Tusks, which are derived from the incisor teeth, serve both as weapons and as tools for moving objects and digging.\n"
     ]
    }
   ],
   "source": [
    "# Get document summary by combining above sentences.\n",
    "for index in top_sentence_indices:\n",
    "    print(sentences[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsa_text_summarizer(documents, num_sentences=2,\n",
    "                        num_topics=2,\n",
    "                        feature_type='frequency',\n",
    "                        sv_threshold=0.5):\n",
    "    vec, dt_matrix = build_feature_matrix(documents, feature_type=feature_type)\n",
    "    td_matrix = dt_matrix.transpose()\n",
    "    td_matrix = td_matrix.multiply(td_matrix > 0)\n",
    "    \n",
    "    u, s, vt = low_rank_svd(td_matrix, singular_count=num_topics)\n",
    "    min_sigma_value = max(s) * sv_threshold\n",
    "    s[s < min_sigma_value] = 0\n",
    "    \n",
    "    salience_scores = np.sqrt(np.dot(np.square(s), np.square(vt)))\n",
    "\n",
    "    top_sentence_indices = salience_scores.argsort()[-num_sentences:][::-1]\n",
    "    top_sentence_indices.sort()\n",
    "    \n",
    "    for index in top_sentence_indices:\n",
    "        print(sentences[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three species are currently recognised: the African bush elephant, the African forest elephant, and the Asian elephant.\n",
      "African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs.\n"
     ]
    }
   ],
   "source": [
    "lsa_text_summarizer(sentences, num_topics=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextRank\n",
    "\n",
    "TextRank summarization algorithm internally uses the popular PageRank algorithm, which is used by Google for ranking web sites and pages and measures their importance. It is used by Google search engine when providing relevant web pages based on search queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.12, 0.16, 0.2 , 0.12, 0.09, 0.  , 0.  , 0.06, 0.  ],\n",
       "       [0.12, 1.  , 0.  , 0.1 , 0.31, 0.09, 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.16, 0.  , 1.  , 0.2 , 0.  , 0.06, 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.2 , 0.1 , 0.2 , 1.  , 0.06, 0.09, 0.07, 0.  , 0.  , 0.  ],\n",
       "       [0.12, 0.31, 0.  , 0.06, 1.  , 0.17, 0.  , 0.  , 0.14, 0.  ],\n",
       "       [0.09, 0.09, 0.06, 0.09, 0.17, 1.  , 0.06, 0.07, 0.17, 0.1 ],\n",
       "       [0.  , 0.  , 0.  , 0.07, 0.  , 0.06, 1.  , 0.07, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.07, 1.  , 0.  , 0.  ],\n",
       "       [0.06, 0.  , 0.  , 0.  , 0.14, 0.17, 0.  , 0.  , 1.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.  , 0.  , 1.  ]])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx\n",
    "\n",
    "# Define number of sentences in final summary.\n",
    "num_sentences = 3\n",
    "\n",
    "# Construct weighted document term matrix.\n",
    "vec, dt_matrix = build_feature_matrix(norm_sentences,\n",
    "                                      feature_type='tfidf')\n",
    "\n",
    "# Construct the document similarity matrix.\n",
    "similarity_matrix = (dt_matrix * dt_matrix.T)\n",
    "\n",
    "# View the document similarity matrix.\n",
    "np.round(similarity_matrix.todense(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the similarity graph.\n",
    "similarity_graph = networkx.from_scipy_sparse_matrix(similarity_matrix)\n",
    "networkx.draw_networkx(similarity_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.11983560237015697, 5),\n",
       " (0.10948015981377418, 4),\n",
       " (0.10783338591245924, 0),\n",
       " (0.10739288368086489, 3),\n",
       " (0.09951639026611504, 1),\n",
       " (0.09249454144457596, 2),\n",
       " (0.09152848450028381, 6),\n",
       " (0.09152833600967743, 7),\n",
       " (0.0906350115632551, 8),\n",
       " (0.08975520443883747, 9)]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute pagerank scores for all the sentence.\n",
    "scores = networkx.pagerank(similarity_graph)\n",
    "\n",
    "# Rank sentences based on their scores.\n",
    "ranked_sentences = sorted(((score, index)\n",
    "                           for index, score\n",
    "                           in scores.items()),\n",
    "                          reverse=True)\n",
    "\n",
    "# View the ranked sentences\n",
    "ranked_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top sentence indices for our summary.\n",
    "top_sentence_indices = [ranked_sentences[index][1]\n",
    "                        for index in range(num_sentences)]\n",
    "top_sentence_indices.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 5]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the top sentence indices.\n",
    "top_sentence_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elephants are mammals of the family Elephantidae and the largest existing land animals.\n",
      "African elephants have larger ears and concave backs, whereas Asian elephants have smaller ears, and convex or level backs.\n",
      "Distinctive features of all elephants include a long trunk, tusks, large ear flaps, massive legs, and tough but sensitive skin.\n"
     ]
    }
   ],
   "source": [
    "# Construct the document summary.\n",
    "for index in top_sentence_indices:\n",
    "    print(sentences[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank_text_summarizer(documents, num_sentences=2, \n",
    "                             feature_type='frequency'):\n",
    "    vec, dt_matrix = build_feature_matrix(documents, \n",
    "                                          feature_type='tfidf')\n",
    "    similarity_matrix = (dt_matrix * dt_matrix.T)\n",
    "    similarity_graph = networkx.from_scipy_sparse_matrix(similarity_matrix)\n",
    "    scores = networkx.pagerank(similarity_graph)\n",
    "    \n",
    "    ranked_sentences = sorted(((score, index)\n",
    "                               for index, score\n",
    "                               in scores.items()),\n",
    "                              reverse=True)\n",
    "    \n",
    "    top_sentence_indices = [ranked_sentences[index][1]\n",
    "                            for index in range(num_sentences)]\n",
    "    \n",
    "    top_sentence_indices.sort()\n",
    "    \n",
    "    for index in top_sentence_indices:\n",
    "        print(sentences[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elephants are mammals of the family Elephantidae and the largest existing land animals.\n",
      "Elephantidae is the only surviving family of the order Proboscidea; extinct members include the mastodons.\n",
      "The family Elephantidae also contains several now-extinct groups, including the mammoths and straight-tusked elephants.\n"
     ]
    }
   ],
   "source": [
    "textrank_text_summarizer(sentences, num_sentences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing a product description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENT = \"\"\"\n",
    "The Elder Scrolls V: Skyrim is an open world action role-playing video game \n",
    "developed by Bethesda Game Studios and published by Bethesda Softworks. \n",
    "It is the fifth installment in The Elder Scrolls series, following \n",
    "The Elder Scrolls IV: Oblivion. Skyrim's main story revolves around \n",
    "the player character and their effort to defeat Alduin the World-Eater, \n",
    "a dragon who is prophesied to destroy the world. \n",
    "The game is set two hundred years after the events of Oblivion \n",
    "and takes place in the fictional province of Skyrim. The player completes quests \n",
    "and develops the character by improving skills. \n",
    "Skyrim continues the open world tradition of its predecessors by allowing the \n",
    "player to travel anywhere in the game world at any time, and to \n",
    "ignore or postpone the main storyline indefinitely. The player may freely roam \n",
    "over the land of Skyrim, which is an open world environment consisting \n",
    "of wilderness expanses, dungeons, cities, towns, fortresses and villages. \n",
    "Players may navigate the game world more quickly by riding horses, \n",
    "or by utilizing a fast-travel system which allows them to warp to previously \n",
    "Players have the option to develop their character. At the beginning of the game, \n",
    "players create their character by selecting one of several races, \n",
    "including humans, orcs, elves and anthropomorphic cat or lizard-like creatures, \n",
    "and then customizing their character's appearance.discovered locations. Over the \n",
    "course of the game, players improve their character's skills, which are numerical \n",
    "representations of their ability in certain areas. There are eighteen skills \n",
    "divided evenly among the three schools of combat, magic, and stealth. \n",
    "Skyrim is the first entry in The Elder Scrolls to include Dragons in the game's \n",
    "wilderness. Like other creatures, Dragons are generated randomly in the world \n",
    "and will engage in combat. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Total sentences:', 13)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the document.\n",
    "sentences = parse_document(DOCUMENT)\n",
    "norm_sentences = normalize_corpus(sentences, lemmatize=True)\n",
    "'Total sentences:', len(norm_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skyrim continues the open world tradition of its predecessors by allowing the  player to travel anywhere in the game world at any time, and to  ignore or postpone the main storyline indefinitely.\n",
      "Players may navigate the game world more quickly by riding horses,  or by utilizing a fast-travel system which allows them to warp to previously  Players have the option to develop their character.\n",
      "At the beginning of the game,  players create their character by selecting one of several races,  including humans, orcs, elves and anthropomorphic cat or lizard-like creatures,  and then customizing their character's appearance.discovered locations.\n"
     ]
    }
   ],
   "source": [
    "# LSA document summarization.\n",
    "lsa_text_summarizer(norm_sentences, \n",
    "                    num_sentences=3, \n",
    "                    num_topics=5, \n",
    "                    feature_type='frequency',\n",
    "                    sv_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Elder Scrolls V: Skyrim is an open world action role-playing video game  developed by Bethesda Game Studios and published by Bethesda Softworks.\n",
      "The player completes quests  and develops the character by improving skills.\n",
      "Skyrim is the first entry in The Elder Scrolls to include Dragons in the game's  wilderness.\n"
     ]
    }
   ],
   "source": [
    "# TextRank document summarization.\n",
    "textrank_text_summarizer(norm_sentences, num_sentences=3,\n",
    "                        feature_type='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
